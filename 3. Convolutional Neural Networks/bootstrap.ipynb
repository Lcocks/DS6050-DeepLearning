{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2c41aee-3c16-4649-9339-b54d09a9dc8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/sfs/gpfs/tardis/home/epx8hh/Documents/MSDS/DS6050/DS6050-DeepLearning/3. Convolutional Neural Networks/hydra_optuna_cifar\n",
      "==== Resolved Config ====\n",
      "seed: 0\n",
      "hpo:\n",
      "  seeds:\n",
      "  - 0\n",
      "  - 1\n",
      "  mode: none\n",
      "data:\n",
      "  root: ./data\n",
      "  batch_size: 64\n",
      "  num_workers: 2\n",
      "  augment: false\n",
      "  use_fake: false\n",
      "model:\n",
      "  input_size: 3072\n",
      "  n_layers: 3\n",
      "  hidden_size: 512\n",
      "  norm_type: batch\n",
      "  use_residual: true\n",
      "  init: kaiming_normal\n",
      "  dropout: 0.3\n",
      "  num_classes: 10\n",
      "optimizer:\n",
      "  name: Adam\n",
      "  lr: 0.0003\n",
      "  weight_decay: 0.0001\n",
      "  momentum: 0.9\n",
      "training:\n",
      "  epochs: 3\n",
      "  device: auto\n",
      "  early_stop: false\n",
      "\n",
      "100%|█████████████████████████████████████████| 170M/170M [00:01<00:00, 105MB/s]\n",
      "/home/epx8hh/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "[RESULT] val_acc_mean=0.4657  val_acc_std=0.0083  params=2634250\n",
      "[2025-09-24 18:38:46,207][HYDRA] Launching 12 jobs locally\n",
      "[2025-09-24 18:38:46,207][HYDRA] \t#0 : model.norm_type=none model.use_residual=True data.batch_size=32 hpo.seeds=[0,1]\n",
      "==== Resolved Config ====\n",
      "seed: 0\n",
      "hpo:\n",
      "  seeds:\n",
      "  - 0\n",
      "  - 1\n",
      "  mode: none\n",
      "data:\n",
      "  root: ./data\n",
      "  batch_size: 32\n",
      "  num_workers: 2\n",
      "  augment: false\n",
      "  use_fake: false\n",
      "model:\n",
      "  input_size: 3072\n",
      "  n_layers: 3\n",
      "  hidden_size: 512\n",
      "  norm_type: none\n",
      "  use_residual: true\n",
      "  init: kaiming_normal\n",
      "  dropout: 0.3\n",
      "  num_classes: 10\n",
      "optimizer:\n",
      "  name: Adam\n",
      "  lr: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  momentum: 0.9\n",
      "training:\n",
      "  epochs: 5\n",
      "  device: auto\n",
      "  early_stop: false\n",
      "\n",
      "/home/epx8hh/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "[RESULT] val_acc_mean=0.4569  val_acc_std=0.0003  params=2629130\n",
      "[2025-09-24 18:42:45,631][HYDRA] \t#1 : model.norm_type=none model.use_residual=True data.batch_size=64 hpo.seeds=[0,1]\n",
      "==== Resolved Config ====\n",
      "seed: 0\n",
      "hpo:\n",
      "  seeds:\n",
      "  - 0\n",
      "  - 1\n",
      "  mode: none\n",
      "data:\n",
      "  root: ./data\n",
      "  batch_size: 64\n",
      "  num_workers: 2\n",
      "  augment: false\n",
      "  use_fake: false\n",
      "model:\n",
      "  input_size: 3072\n",
      "  n_layers: 3\n",
      "  hidden_size: 512\n",
      "  norm_type: none\n",
      "  use_residual: true\n",
      "  init: kaiming_normal\n",
      "  dropout: 0.3\n",
      "  num_classes: 10\n",
      "optimizer:\n",
      "  name: Adam\n",
      "  lr: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  momentum: 0.9\n",
      "training:\n",
      "  epochs: 5\n",
      "  device: auto\n",
      "  early_stop: false\n",
      "\n",
      "[RESULT] val_acc_mean=0.4903  val_acc_std=0.0091  params=2629130\n",
      "[2025-09-24 18:45:36,046][HYDRA] \t#2 : model.norm_type=none model.use_residual=False data.batch_size=32 hpo.seeds=[0,1]\n",
      "==== Resolved Config ====\n",
      "seed: 0\n",
      "hpo:\n",
      "  seeds:\n",
      "  - 0\n",
      "  - 1\n",
      "  mode: none\n",
      "data:\n",
      "  root: ./data\n",
      "  batch_size: 32\n",
      "  num_workers: 2\n",
      "  augment: false\n",
      "  use_fake: false\n",
      "model:\n",
      "  input_size: 3072\n",
      "  n_layers: 3\n",
      "  hidden_size: 512\n",
      "  norm_type: none\n",
      "  use_residual: false\n",
      "  init: kaiming_normal\n",
      "  dropout: 0.3\n",
      "  num_classes: 10\n",
      "optimizer:\n",
      "  name: Adam\n",
      "  lr: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  momentum: 0.9\n",
      "training:\n",
      "  epochs: 5\n",
      "  device: auto\n",
      "  early_stop: false\n",
      "\n",
      "[RESULT] val_acc_mean=0.4319  val_acc_std=0.0001  params=2103818\n",
      "[2025-09-24 18:49:07,657][HYDRA] \t#3 : model.norm_type=none model.use_residual=False data.batch_size=64 hpo.seeds=[0,1]\n",
      "==== Resolved Config ====\n",
      "seed: 0\n",
      "hpo:\n",
      "  seeds:\n",
      "  - 0\n",
      "  - 1\n",
      "  mode: none\n",
      "data:\n",
      "  root: ./data\n",
      "  batch_size: 64\n",
      "  num_workers: 2\n",
      "  augment: false\n",
      "  use_fake: false\n",
      "model:\n",
      "  input_size: 3072\n",
      "  n_layers: 3\n",
      "  hidden_size: 512\n",
      "  norm_type: none\n",
      "  use_residual: false\n",
      "  init: kaiming_normal\n",
      "  dropout: 0.3\n",
      "  num_classes: 10\n",
      "optimizer:\n",
      "  name: Adam\n",
      "  lr: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  momentum: 0.9\n",
      "training:\n",
      "  epochs: 5\n",
      "  device: auto\n",
      "  early_stop: false\n",
      "\n",
      "[RESULT] val_acc_mean=0.4580  val_acc_std=0.0057  params=2103818\n",
      "[2025-09-24 18:51:32,805][HYDRA] \t#4 : model.norm_type=batch model.use_residual=True data.batch_size=32 hpo.seeds=[0,1]\n",
      "==== Resolved Config ====\n",
      "seed: 0\n",
      "hpo:\n",
      "  seeds:\n",
      "  - 0\n",
      "  - 1\n",
      "  mode: none\n",
      "data:\n",
      "  root: ./data\n",
      "  batch_size: 32\n",
      "  num_workers: 2\n",
      "  augment: false\n",
      "  use_fake: false\n",
      "model:\n",
      "  input_size: 3072\n",
      "  n_layers: 3\n",
      "  hidden_size: 512\n",
      "  norm_type: batch\n",
      "  use_residual: true\n",
      "  init: kaiming_normal\n",
      "  dropout: 0.3\n",
      "  num_classes: 10\n",
      "optimizer:\n",
      "  name: Adam\n",
      "  lr: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  momentum: 0.9\n",
      "training:\n",
      "  epochs: 5\n",
      "  device: auto\n",
      "  early_stop: false\n",
      "\n",
      "[RESULT] val_acc_mean=0.4889  val_acc_std=0.0071  params=2634250\n",
      "[2025-09-24 18:55:44,001][HYDRA] \t#5 : model.norm_type=batch model.use_residual=True data.batch_size=64 hpo.seeds=[0,1]\n",
      "==== Resolved Config ====\n",
      "seed: 0\n",
      "hpo:\n",
      "  seeds:\n",
      "  - 0\n",
      "  - 1\n",
      "  mode: none\n",
      "data:\n",
      "  root: ./data\n",
      "  batch_size: 64\n",
      "  num_workers: 2\n",
      "  augment: false\n",
      "  use_fake: false\n",
      "model:\n",
      "  input_size: 3072\n",
      "  n_layers: 3\n",
      "  hidden_size: 512\n",
      "  norm_type: batch\n",
      "  use_residual: true\n",
      "  init: kaiming_normal\n",
      "  dropout: 0.3\n",
      "  num_classes: 10\n",
      "optimizer:\n",
      "  name: Adam\n",
      "  lr: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  momentum: 0.9\n",
      "training:\n",
      "  epochs: 5\n",
      "  device: auto\n",
      "  early_stop: false\n",
      "\n",
      "[RESULT] val_acc_mean=0.5008  val_acc_std=0.0041  params=2634250\n",
      "[2025-09-24 18:58:45,809][HYDRA] \t#6 : model.norm_type=batch model.use_residual=False data.batch_size=32 hpo.seeds=[0,1]\n",
      "==== Resolved Config ====\n",
      "seed: 0\n",
      "hpo:\n",
      "  seeds:\n",
      "  - 0\n",
      "  - 1\n",
      "  mode: none\n",
      "data:\n",
      "  root: ./data\n",
      "  batch_size: 32\n",
      "  num_workers: 2\n",
      "  augment: false\n",
      "  use_fake: false\n",
      "model:\n",
      "  input_size: 3072\n",
      "  n_layers: 3\n",
      "  hidden_size: 512\n",
      "  norm_type: batch\n",
      "  use_residual: false\n",
      "  init: kaiming_normal\n",
      "  dropout: 0.3\n",
      "  num_classes: 10\n",
      "optimizer:\n",
      "  name: Adam\n",
      "  lr: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  momentum: 0.9\n",
      "training:\n",
      "  epochs: 5\n",
      "  device: auto\n",
      "  early_stop: false\n",
      "\n",
      "[RESULT] val_acc_mean=0.4965  val_acc_std=0.0000  params=2106890\n",
      "[2025-09-24 19:02:26,458][HYDRA] \t#7 : model.norm_type=batch model.use_residual=False data.batch_size=64 hpo.seeds=[0,1]\n",
      "==== Resolved Config ====\n",
      "seed: 0\n",
      "hpo:\n",
      "  seeds:\n",
      "  - 0\n",
      "  - 1\n",
      "  mode: none\n",
      "data:\n",
      "  root: ./data\n",
      "  batch_size: 64\n",
      "  num_workers: 2\n",
      "  augment: false\n",
      "  use_fake: false\n",
      "model:\n",
      "  input_size: 3072\n",
      "  n_layers: 3\n",
      "  hidden_size: 512\n",
      "  norm_type: batch\n",
      "  use_residual: false\n",
      "  init: kaiming_normal\n",
      "  dropout: 0.3\n",
      "  num_classes: 10\n",
      "optimizer:\n",
      "  name: Adam\n",
      "  lr: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  momentum: 0.9\n",
      "training:\n",
      "  epochs: 5\n",
      "  device: auto\n",
      "  early_stop: false\n",
      "\n",
      "[RESULT] val_acc_mean=0.5049  val_acc_std=0.0035  params=2106890\n",
      "[2025-09-24 19:04:58,189][HYDRA] \t#8 : model.norm_type=layer model.use_residual=True data.batch_size=32 hpo.seeds=[0,1]\n",
      "==== Resolved Config ====\n",
      "seed: 0\n",
      "hpo:\n",
      "  seeds:\n",
      "  - 0\n",
      "  - 1\n",
      "  mode: none\n",
      "data:\n",
      "  root: ./data\n",
      "  batch_size: 32\n",
      "  num_workers: 2\n",
      "  augment: false\n",
      "  use_fake: false\n",
      "model:\n",
      "  input_size: 3072\n",
      "  n_layers: 3\n",
      "  hidden_size: 512\n",
      "  norm_type: layer\n",
      "  use_residual: true\n",
      "  init: kaiming_normal\n",
      "  dropout: 0.3\n",
      "  num_classes: 10\n",
      "optimizer:\n",
      "  name: Adam\n",
      "  lr: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  momentum: 0.9\n",
      "training:\n",
      "  epochs: 5\n",
      "  device: auto\n",
      "  early_stop: false\n",
      "\n",
      "[RESULT] val_acc_mean=0.4936  val_acc_std=0.0105  params=2634250\n",
      "[2025-09-24 19:09:30,404][HYDRA] \t#9 : model.norm_type=layer model.use_residual=True data.batch_size=64 hpo.seeds=[0,1]\n",
      "==== Resolved Config ====\n",
      "seed: 0\n",
      "hpo:\n",
      "  seeds:\n",
      "  - 0\n",
      "  - 1\n",
      "  mode: none\n",
      "data:\n",
      "  root: ./data\n",
      "  batch_size: 64\n",
      "  num_workers: 2\n",
      "  augment: false\n",
      "  use_fake: false\n",
      "model:\n",
      "  input_size: 3072\n",
      "  n_layers: 3\n",
      "  hidden_size: 512\n",
      "  norm_type: layer\n",
      "  use_residual: true\n",
      "  init: kaiming_normal\n",
      "  dropout: 0.3\n",
      "  num_classes: 10\n",
      "optimizer:\n",
      "  name: Adam\n",
      "  lr: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  momentum: 0.9\n",
      "training:\n",
      "  epochs: 5\n",
      "  device: auto\n",
      "  early_stop: false\n",
      "\n",
      "[RESULT] val_acc_mean=0.4991  val_acc_std=0.0096  params=2634250\n",
      "[2025-09-24 19:12:32,738][HYDRA] \t#10 : model.norm_type=layer model.use_residual=False data.batch_size=32 hpo.seeds=[0,1]\n",
      "==== Resolved Config ====\n",
      "seed: 0\n",
      "hpo:\n",
      "  seeds:\n",
      "  - 0\n",
      "  - 1\n",
      "  mode: none\n",
      "data:\n",
      "  root: ./data\n",
      "  batch_size: 32\n",
      "  num_workers: 2\n",
      "  augment: false\n",
      "  use_fake: false\n",
      "model:\n",
      "  input_size: 3072\n",
      "  n_layers: 3\n",
      "  hidden_size: 512\n",
      "  norm_type: layer\n",
      "  use_residual: false\n",
      "  init: kaiming_normal\n",
      "  dropout: 0.3\n",
      "  num_classes: 10\n",
      "optimizer:\n",
      "  name: Adam\n",
      "  lr: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  momentum: 0.9\n",
      "training:\n",
      "  epochs: 5\n",
      "  device: auto\n",
      "  early_stop: false\n",
      "\n",
      "[RESULT] val_acc_mean=0.4834  val_acc_std=0.0030  params=2106890\n",
      "[2025-09-24 19:16:10,733][HYDRA] \t#11 : model.norm_type=layer model.use_residual=False data.batch_size=64 hpo.seeds=[0,1]\n",
      "==== Resolved Config ====\n",
      "seed: 0\n",
      "hpo:\n",
      "  seeds:\n",
      "  - 0\n",
      "  - 1\n",
      "  mode: none\n",
      "data:\n",
      "  root: ./data\n",
      "  batch_size: 64\n",
      "  num_workers: 2\n",
      "  augment: false\n",
      "  use_fake: false\n",
      "model:\n",
      "  input_size: 3072\n",
      "  n_layers: 3\n",
      "  hidden_size: 512\n",
      "  norm_type: layer\n",
      "  use_residual: false\n",
      "  init: kaiming_normal\n",
      "  dropout: 0.3\n",
      "  num_classes: 10\n",
      "optimizer:\n",
      "  name: Adam\n",
      "  lr: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  momentum: 0.9\n",
      "training:\n",
      "  epochs: 5\n",
      "  device: auto\n",
      "  early_stop: false\n",
      "\n",
      "[RESULT] val_acc_mean=0.4950  val_acc_std=0.0035  params=2106890\n",
      "In 'experiment/hpo': Could not override 'experiment/hydra/sweeper'. No match in the defaults list.\n",
      "\n",
      "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n"
     ]
    }
   ],
   "source": [
    "# 1) Install deps\n",
    "!pip -q install hydra-core hydra-optuna-sweeper optuna torch torchvision\n",
    "\n",
    "# 2) Upload ZIP (if you haven't already) or fetch from local cell output\n",
    "#    In this chat, download the provided file and then upload it to Colab.\n",
    "#    Or if you placed it in /. already, just unzip:\n",
    "import zipfile, os\n",
    "\n",
    "zip_path = \"./hydra_optuna_cifar.zip\"  # <- upload the ZIP here via Colab \"Files\" sidebar\n",
    "assert os.path.exists(zip_path), \"Upload hydra_optuna_cifar.zip to /. first (Files sidebar)\"\n",
    "with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "    z.extractall(\".\")\n",
    "\n",
    "# 3) Enter the project\n",
    "%cd ./hydra_optuna_cifar\n",
    "\n",
    "# 4) Single run (no sweeper): simple override from CLI\n",
    "!python train.py training.epochs=3 optimizer.lr=3e-4 data.batch_size=64\n",
    "\n",
    "# 5) Factorial ablation (Hydra multirun enumerates the “outer” design questions)\n",
    "!python train.py -m model.norm_type=none,batch,layer model.use_residual=true,false data.batch_size=32,64 hpo.seeds=[0,1]\n",
    "\n",
    "# 6) HPO (Hydra Optuna Sweeper) = \"best-of-each\" tuning per design\n",
    "!python train.py -m +experiment=hpo hpo.seeds=[0,1,2]\n",
    "\n",
    "# (Optional) Programmatic Optuna (per-epoch pruning support):\n",
    "# Edit conf/config.yaml -> set hpo.mode=\"optuna_programmatic\", then:\n",
    "# !python train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7213249a-3e43-4b38-8390-af12ec742775",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsvenv",
   "language": "python",
   "name": "dsvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
