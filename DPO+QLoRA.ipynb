{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ac0ad8e9831a49ed95e8129028159434": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c41d8a59c1f84c12b94880fb36be7fb9",
              "IPY_MODEL_63d9684870c240c6909249deee75a920",
              "IPY_MODEL_a573c43d12a34429b97934973cfa3530"
            ],
            "layout": "IPY_MODEL_2143e61b7f044725a5a62fefc0a28292"
          }
        },
        "c41d8a59c1f84c12b94880fb36be7fb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53ceb5e2f3c64f6da6613bebdcffff41",
            "placeholder": "​",
            "style": "IPY_MODEL_70b0a42cb3094302a99111d0b337fc6b",
            "value": "Map: 100%"
          }
        },
        "63d9684870c240c6909249deee75a920": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3dfd79a02dcc44fa87f96e1efdd72689",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2c59f80f5aeb4a25b8d9c8051c909f37",
            "value": 20
          }
        },
        "a573c43d12a34429b97934973cfa3530": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d59d537c524f4da0b8af07d7d8090506",
            "placeholder": "​",
            "style": "IPY_MODEL_03668ad94c704119a5f82238c96466ba",
            "value": " 20/20 [00:00&lt;00:00, 1331.12 examples/s]"
          }
        },
        "2143e61b7f044725a5a62fefc0a28292": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53ceb5e2f3c64f6da6613bebdcffff41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70b0a42cb3094302a99111d0b337fc6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3dfd79a02dcc44fa87f96e1efdd72689": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c59f80f5aeb4a25b8d9c8051c909f37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d59d537c524f4da0b8af07d7d8090506": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03668ad94c704119a5f82238c96466ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b71d8c8dfea4885b6d454f30b4680b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_150c0b7027644b74ae59da2c69ba8416",
              "IPY_MODEL_65739075dfea42e480f6dd009151d6b8",
              "IPY_MODEL_2698702544924ebaa93917ef165c8f1e"
            ],
            "layout": "IPY_MODEL_41aa4da3afb748bd9660866d8141f3a1"
          }
        },
        "150c0b7027644b74ae59da2c69ba8416": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6a9cb27bbf64411861d49d9639a4a62",
            "placeholder": "​",
            "style": "IPY_MODEL_cae1f37dfaea48d1af8f91c8c7d3d83a",
            "value": "Extracting prompt in train dataset: 100%"
          }
        },
        "65739075dfea42e480f6dd009151d6b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a68ac4ed07e444a9b0590a8a52769bf",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d9eec696253d4f798cc5f42845bdb29d",
            "value": 20
          }
        },
        "2698702544924ebaa93917ef165c8f1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b0790d91a18420990f00cba42d3fb27",
            "placeholder": "​",
            "style": "IPY_MODEL_f3988b8ac9dc47f0a8b65cfac79f6554",
            "value": " 20/20 [00:00&lt;00:00, 1508.93 examples/s]"
          }
        },
        "41aa4da3afb748bd9660866d8141f3a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6a9cb27bbf64411861d49d9639a4a62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cae1f37dfaea48d1af8f91c8c7d3d83a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a68ac4ed07e444a9b0590a8a52769bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9eec696253d4f798cc5f42845bdb29d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9b0790d91a18420990f00cba42d3fb27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3988b8ac9dc47f0a8b65cfac79f6554": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01f33cb6af2b468fb1506290d036af77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_170c506c22bf406a957e22fbb08a3229",
              "IPY_MODEL_c15a61b907854a3aa7052ab1fa48fb17",
              "IPY_MODEL_2fde595f31a1470e95120fe510c7a147"
            ],
            "layout": "IPY_MODEL_7f79017bf9d241d38769b363dd486381"
          }
        },
        "170c506c22bf406a957e22fbb08a3229": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0208cb0f9b7a45e6898cf07975a8ee29",
            "placeholder": "​",
            "style": "IPY_MODEL_cdcadb8d14ed436f90d823e89b1e4060",
            "value": "Applying chat template to train dataset: 100%"
          }
        },
        "c15a61b907854a3aa7052ab1fa48fb17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d7e8c0994774da5b8d2b13db4fec25a",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_76ff4627fec642498117fab2c8b4462e",
            "value": 20
          }
        },
        "2fde595f31a1470e95120fe510c7a147": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_893bc33ea2b04138a62f0029e1cda266",
            "placeholder": "​",
            "style": "IPY_MODEL_7c4988d463bd4f1d99a93c64166a4df5",
            "value": " 20/20 [00:00&lt;00:00, 1391.01 examples/s]"
          }
        },
        "7f79017bf9d241d38769b363dd486381": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0208cb0f9b7a45e6898cf07975a8ee29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdcadb8d14ed436f90d823e89b1e4060": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d7e8c0994774da5b8d2b13db4fec25a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76ff4627fec642498117fab2c8b4462e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "893bc33ea2b04138a62f0029e1cda266": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c4988d463bd4f1d99a93c64166a4df5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a8b2c313ec043fa8cf50f4137267994": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f5965ba0ce954ee6a984095bd95f20ad",
              "IPY_MODEL_eeb31df13ed040f1a0fb430756cdc99d",
              "IPY_MODEL_66bb65a4ba56445daeffa8a49dbe9cc1"
            ],
            "layout": "IPY_MODEL_8affedcef3744e95a0d067b865b15033"
          }
        },
        "f5965ba0ce954ee6a984095bd95f20ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0262a3497acd4d67be1f272eeb479994",
            "placeholder": "​",
            "style": "IPY_MODEL_3e892ccf7f224d20aa9a335996e53914",
            "value": "Tokenizing train dataset: 100%"
          }
        },
        "eeb31df13ed040f1a0fb430756cdc99d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d22c6c342a04ad4b9970eb6324cc38a",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0835e40cb22a4864a0ce2efe9a745503",
            "value": 20
          }
        },
        "66bb65a4ba56445daeffa8a49dbe9cc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d9c2b6d3c134d1589fec9c7b1674d17",
            "placeholder": "​",
            "style": "IPY_MODEL_dbbc4a2d9c7c4a94aa430aafd7eb931c",
            "value": " 20/20 [00:00&lt;00:00, 774.06 examples/s]"
          }
        },
        "8affedcef3744e95a0d067b865b15033": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0262a3497acd4d67be1f272eeb479994": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e892ccf7f224d20aa9a335996e53914": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d22c6c342a04ad4b9970eb6324cc38a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0835e40cb22a4864a0ce2efe9a745503": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0d9c2b6d3c134d1589fec9c7b1674d17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbbc4a2d9c7c4a94aa430aafd7eb931c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lcocks/DS6050-DeepLearning/blob/main/DPO%2BQLoRA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================================================\n",
        "# LLM Alignment in Practice: Direct Preference Optimization (DPO)\n",
        "#\n",
        "# This notebook demonstrates how to align a language model using DPO with QLoRA.\n",
        "# We connect concepts from our PEFT and Alignment lectures.\n",
        "#\n",
        "# Learning Goals:\n",
        "# 1. Understand preference data format\n",
        "# 2. Apply QLoRA for memory-efficient alignment\n",
        "# 3. Use Hugging Face TRL (Transformer Reinforcement Learning) library\n",
        "# 4. Compare model behavior before and after alignment\n",
        "# ====================================================================================\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# CELL 1: Installation\n",
        "# -----------------------------------------------------------------------------\n",
        "\"\"\"\n",
        "Install required packages. This may take a few minutes.\n",
        "Run this cell first, then restart the runtime if needed.\n",
        "\"\"\"\n",
        "\n",
        "!pip install -q torch transformers datasets trl peft accelerate bitsandbytes\n"
      ],
      "metadata": {
        "id": "dyPgDNwvi33j",
        "outputId": "5f1856ac-69b8-4023-aefd-4d194c6b6124",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.5/465.5 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "wz0D43bfhoi8",
        "outputId": "e64bdfa7-a468-41fe-f879-d2601f5150d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ac0ad8e9831a49ed95e8129028159434",
            "c41d8a59c1f84c12b94880fb36be7fb9",
            "63d9684870c240c6909249deee75a920",
            "a573c43d12a34429b97934973cfa3530",
            "2143e61b7f044725a5a62fefc0a28292",
            "53ceb5e2f3c64f6da6613bebdcffff41",
            "70b0a42cb3094302a99111d0b337fc6b",
            "3dfd79a02dcc44fa87f96e1efdd72689",
            "2c59f80f5aeb4a25b8d9c8051c909f37",
            "d59d537c524f4da0b8af07d7d8090506",
            "03668ad94c704119a5f82238c96466ba",
            "8b71d8c8dfea4885b6d454f30b4680b4",
            "150c0b7027644b74ae59da2c69ba8416",
            "65739075dfea42e480f6dd009151d6b8",
            "2698702544924ebaa93917ef165c8f1e",
            "41aa4da3afb748bd9660866d8141f3a1",
            "d6a9cb27bbf64411861d49d9639a4a62",
            "cae1f37dfaea48d1af8f91c8c7d3d83a",
            "0a68ac4ed07e444a9b0590a8a52769bf",
            "d9eec696253d4f798cc5f42845bdb29d",
            "9b0790d91a18420990f00cba42d3fb27",
            "f3988b8ac9dc47f0a8b65cfac79f6554",
            "01f33cb6af2b468fb1506290d036af77",
            "170c506c22bf406a957e22fbb08a3229",
            "c15a61b907854a3aa7052ab1fa48fb17",
            "2fde595f31a1470e95120fe510c7a147",
            "7f79017bf9d241d38769b363dd486381",
            "0208cb0f9b7a45e6898cf07975a8ee29",
            "cdcadb8d14ed436f90d823e89b1e4060",
            "4d7e8c0994774da5b8d2b13db4fec25a",
            "76ff4627fec642498117fab2c8b4462e",
            "893bc33ea2b04138a62f0029e1cda266",
            "7c4988d463bd4f1d99a93c64166a4df5",
            "6a8b2c313ec043fa8cf50f4137267994",
            "f5965ba0ce954ee6a984095bd95f20ad",
            "eeb31df13ed040f1a0fb430756cdc99d",
            "66bb65a4ba56445daeffa8a49dbe9cc1",
            "8affedcef3744e95a0d067b865b15033",
            "0262a3497acd4d67be1f272eeb479994",
            "3e892ccf7f224d20aa9a335996e53914",
            "0d22c6c342a04ad4b9970eb6324cc38a",
            "0835e40cb22a4864a0ce2efe9a745503",
            "0d9c2b6d3c134d1589fec9c7b1674d17",
            "dbbc4a2d9c7c4a94aa430aafd7eb931c"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.8.0+cu126\n",
            "CUDA available: True\n",
            "GPU: NVIDIA A100-SXM4-40GB\n",
            "Created preference dataset with 20 examples\n",
            "\n",
            "Example:\n",
            "Prompt: What is the weather forecast for tomorrow? Respond in a formal manner.\n",
            "Chosen: The forecast indicates clear skies with temperatures reaching 75°F tomorrow. No ...\n",
            "Rejected: It looks like it will be sunny and warm tomorrow! ☀️ Perfect day for a walk! 🚶...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac0ad8e9831a49ed95e8129028159434"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formatted prompt example (first 200 chars):\n",
            "<|user|>\n",
            "What is the weather forecast for tomorrow? Respond in a formal manner.</s>\n",
            "<|assistant|>\n",
            "\n",
            "QLoRA Configuration:\n",
            "  - 4-bit quantization: NF4\n",
            "  - LoRA rank: 16\n",
            "  - Trainable parameters: ~0.5M (vs ~1100M full model)\n",
            "Loading model with 4-bit quantization...\n",
            "Model loaded: TinyLlama/TinyLlama-1.1B-Chat-v1.0\n",
            "Model dtype: torch.float16\n",
            "Memory footprint: ~0.75 GB\n",
            "DPO Configuration:\n",
            "  - Beta (KL penalty): 0.01 (lower = more change allowed)\n",
            "  - Learning rate: 5e-05\n",
            "  - Training epochs: 10\n",
            "  - Effective batch size: 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extracting prompt in train dataset:   0%|          | 0/20 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8b71d8c8dfea4885b6d454f30b4680b4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Applying chat template to train dataset:   0%|          | 0/20 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "01f33cb6af2b468fb1506290d036af77"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing train dataset:   0%|          | 0/20 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a8b2c313ec043fa8cf50f4137267994"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 2}.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DPO Trainer initialized successfully!\n",
            "Training on 20 preference pairs\n",
            "Starting DPO training...\n",
            "This will take 10-15 minutes on Colab T4 GPU.\n",
            "Watch the loss - it should decrease steadily!\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [30/30 00:51, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.693100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.677000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.657500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.619100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.577900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.535100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.504800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.467700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.447800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.384300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.372300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.338300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.294400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.268000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.244500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.216700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.188600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.159200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.145900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.128100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.139000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.118900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.094900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.103600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.099900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.084500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.093300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.085200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.081200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.085600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Training complete!\n",
            "\n",
            "📊 Check your final loss:\n",
            "  - Loss < 0.4: Excellent alignment\n",
            "  - Loss 0.4-0.5: Good alignment\n",
            "  - Loss > 0.6: Might need more epochs or lower beta\n",
            "Adapters saved to: ./dpo_aligned_adapters\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# CELL 2: Imports and Setup\n",
        "# -----------------------------------------------------------------------------\n",
        "\"\"\"\n",
        "Import necessary libraries from the Hugging Face ecosystem.\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    BitsAndBytesConfig\n",
        ")\n",
        "from peft import LoraConfig, PeftModel\n",
        "from trl import DPOTrainer, DPOConfig\n",
        "import gc\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# CELL 3: Understanding Preference Data\n",
        "# -----------------------------------------------------------------------------\n",
        "\"\"\"\n",
        "From the lecture: Stage 2 of RLHF - Preference Data Collection\n",
        "\n",
        "In alignment, we don't write \"perfect\" responses (hard!).\n",
        "Instead, we collect PREFERENCES: given two responses, which is better?\n",
        "\n",
        "Required format:\n",
        "- 'prompt': The user's question/instruction\n",
        "- 'chosen': The preferred response (y_w - winner)\n",
        "- 'rejected': The dispreferred response (y_l - loser)\n",
        "\n",
        "EXAMPLE:\n",
        "TinyLlama-Chat is ALREADY very enthusiastic with emojis!\n",
        "So we'll do the OPPOSITE: align it to be more formal and professional.\n",
        "This creates a clear, observable behavioral shift.\n",
        "\n",
        "IMPORTANT: We're training the model to prefer formal, professional responses\n",
        "over casual, emoji-filled ones. This works better pedagogically because\n",
        "we're changing the model's existing behavior rather than reinforcing it.\n",
        "\"\"\"\n",
        "\n",
        "preference_data = {\n",
        "    #original\n",
        "    # \"prompt\": [\n",
        "    #     \"What is the weather forecast for tomorrow?\",\n",
        "    #     \"Did you hear the news about the new library opening?\",\n",
        "    #     \"Can you explain how photosynthesis works?\",\n",
        "    #     \"What are the benefits of reading books?\",\n",
        "    #     \"Tell me about the concert last night.\",\n",
        "    #     \"How do I bake a chocolate cake?\",\n",
        "    #     \"What's the best way to learn programming?\",\n",
        "    #     \"Why is exercise important?\",\n",
        "    #     \"What happened in the football game?\",\n",
        "    #     \"How can I improve my memory?\",\n",
        "    #     \"What makes a good movie?\",\n",
        "    #     \"Why should I drink more water?\",\n",
        "    #     \"Tell me about classical music.\",\n",
        "    #     \"How do plants grow?\",\n",
        "    #     \"What's good about traveling?\",\n",
        "    #     \"Why is sleep important?\",\n",
        "    #     \"What are hobbies good for?\",\n",
        "    #     \"How does recycling help?\",\n",
        "    #     \"What makes a friendship strong?\",\n",
        "    #     \"Why learn history?\",\n",
        "    # ],\n",
        "\n",
        "    #now testing with formal request input.\n",
        "    \"prompt\": [\n",
        "        \"What is the weather forecast for tomorrow? Respond in a formal manner.\",\n",
        "        \"Did you hear the news about the new library opening? Respond in a formal manner.\",\n",
        "        \"Can you explain how photosynthesis works? Respond in a formal manner.\",\n",
        "        \"What are the benefits of reading books? Respond in a formal manner.\",\n",
        "        \"Tell me about the concert last night. Respond in a formal manner.\",\n",
        "        \"How do I bake a chocolate cake? Respond in a formal manner.\",\n",
        "        \"What's the best way to learn programming? Respond in a formal manner.\",\n",
        "        \"Why is exercise important? Respond in a formal manner.\",\n",
        "        \"What happened in the football game? Respond in a formal manner.\",\n",
        "        \"How can I improve my memory? Respond in a formal manner.\",\n",
        "        \"What makes a good movie? Respond in a formal manner.\",\n",
        "        \"Why should I drink more water? Respond in a formal manner.\",\n",
        "        \"Tell me about classical music. Respond in a formal manner.\",\n",
        "        \"How do plants grow? Respond in a formal manner.\",\n",
        "        \"What's good about traveling? Respond in a formal manner.\",\n",
        "        \"Why is sleep important? Respond in a formal manner.\",\n",
        "        \"What are hobbies good for? Respond in a formal manner.\",\n",
        "        \"How does recycling help? Respond in a formal manner.\",\n",
        "        \"What makes a friendship strong? Respond in a formal manner.\",\n",
        "        \"Why learn history? Respond in a formal manner.\",\n",
        "    ],\n",
        "    \"chosen\": [\n",
        "        # Formal, professional responses (what we NOW WANT)\n",
        "        \"The forecast indicates clear skies with temperatures reaching 75°F tomorrow. No precipitation is expected.\",\n",
        "        \"I am aware of the announcement regarding the new library opening. It will serve as a valuable community resource.\",\n",
        "        \"Photosynthesis is the biochemical process by which plants convert light energy into chemical energy, producing glucose and oxygen.\",\n",
        "        \"Reading provides numerous cognitive benefits including vocabulary expansion, improved concentration, and knowledge acquisition.\",\n",
        "        \"The concert featured multiple musical performances with professional execution across various genres.\",\n",
        "        \"To prepare chocolate cake, combine flour, cocoa powder, eggs, sugar, and butter. Bake at 350°F for 30-35 minutes.\",\n",
        "        \"Programming proficiency can be developed through systematic study of computer science fundamentals and regular practice.\",\n",
        "        \"Regular physical exercise contributes to cardiovascular health, muscular strength, and overall physiological well-being.\",\n",
        "        \"The football match concluded with the home team securing a 2-1 victory in the final minutes of play.\",\n",
        "        \"Memory retention can be enhanced through spaced repetition techniques, adequate sleep, and consistent cognitive engagement.\",\n",
        "        \"High-quality cinema demonstrates strong narrative structure, well-developed characters, and thoughtful thematic exploration.\",\n",
        "        \"Adequate hydration supports metabolic processes, cognitive function, and maintains optimal body temperature regulation.\",\n",
        "        \"Classical music represents a Western art music tradition characterized by complex harmonic structures and formal composition.\",\n",
        "        \"Plant development requires photosynthesis, water absorption through roots, and nutrient uptake from surrounding soil.\",\n",
        "        \"International travel facilitates cultural exchange, broadens perspectives, and provides educational opportunities.\",\n",
        "        \"Sleep is essential for memory consolidation, cellular repair, and maintaining cognitive performance.\",\n",
        "        \"Recreational activities provide stress reduction, skill development, and contribute to overall life satisfaction.\",\n",
        "        \"Recycling programs reduce landfill waste, conserve natural resources, and minimize environmental degradation.\",\n",
        "        \"Strong interpersonal relationships are built on mutual trust, consistent support, and shared experiences.\",\n",
        "        \"Historical study provides contextual understanding of contemporary society and insight into human development.\",\n",
        "    ],\n",
        "    \"rejected\": [\n",
        "        # Casual, emoji-filled responses (what we DON'T WANT anymore)\n",
        "        \"It looks like it will be sunny and warm tomorrow! ☀️ Perfect day for a walk! 🚶\",\n",
        "        \"Yes, that's amazing news! 📚 A new library is a fantastic addition to the community! 🎉\",\n",
        "        \"Absolutely! Photosynthesis is the incredible process plants use to create energy from sunlight! 🌱 It's vital for all life! 🌍\",\n",
        "        \"Reading is incredible! 🤩 It expands your vocabulary, improves focus, and opens doors to new worlds! 📖\",\n",
        "        \"The concert was absolutely spectacular! 🎸 The energy was electric and everyone was dancing! 💃🕺\",\n",
        "        \"Baking chocolate cake is so much fun! 🍰 Just mix flour, cocoa, eggs and sugar, then bake at 350°F! Delicious! 😋\",\n",
        "        \"Learning programming is exciting! 💻 Start with Python - it's beginner-friendly and super powerful! 🚀\",\n",
        "        \"Exercise is wonderful! 💪 It boosts your mood, energy, and keeps you healthy! 🏃‍♀️\",\n",
        "        \"What an exciting game! ⚽ The home team scored in the last minute for a thrilling 2-1 victory! 🎉\",\n",
        "        \"Great question! 🧠 Try spaced repetition, get good sleep, and stay active - it really helps! ✨\",\n",
        "        \"A good movie has compelling characters, an engaging plot, and leaves you thinking! 🎬 So powerful! ❤️\",\n",
        "        \"Water is essential! 💧 It energizes you, helps your brain, and keeps everything running smoothly! 💪\",\n",
        "        \"Classical music is beautiful! 🎵 It's calming, complex, and has stood the test of time! 🎻\",\n",
        "        \"Plants are amazing! 🌱 They need sunlight, water, and nutrients to grow big and strong! 🌻\",\n",
        "        \"Traveling is awesome! ✈️ You experience new cultures, foods, and perspectives! 🌎\",\n",
        "        \"Sleep is crucial! 😴 It helps your brain consolidate memories and repairs your body! 💤\",\n",
        "        \"Hobbies are fantastic! 🎨 They reduce stress, teach new skills, and bring joy! 😊\",\n",
        "        \"Recycling is important! ♻️ It reduces waste, saves resources, and protects our planet! 🌍\",\n",
        "        \"True friendships are built on trust, support, and shared experiences! 👯 So valuable! ❤️\",\n",
        "        \"History teaches us about our past and helps us understand the present! 📜 Fascinating! 🤔\",\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Convert to Hugging Face Dataset\n",
        "dataset = Dataset.from_dict(preference_data)\n",
        "print(f\"Created preference dataset with {len(dataset)} examples\")\n",
        "print(f\"\\nExample:\")\n",
        "print(f\"Prompt: {dataset[0]['prompt']}\")\n",
        "print(f\"Chosen: {dataset[0]['chosen'][:80]}...\")\n",
        "print(f\"Rejected: {dataset[0]['rejected'][:80]}...\")\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# CELL 4: Model Selection and Chat Template\n",
        "# -----------------------------------------------------------------------------\n",
        "\"\"\"\n",
        "LECTURE CONNECTION: Stage 1 of RLHF - Starting from SFT Model\n",
        "\n",
        "We start with an instruction-tuned model (the output of SFT).\n",
        "TinyLlama is small (1.1B parameters) - perfect for education and fast iteration.\n",
        "\n",
        "IMPORTANT: Different models use different chat templates (ChatML, Llama format, etc.)\n",
        "We must format prompts correctly using the tokenizer's template.\n",
        "\"\"\"\n",
        "\n",
        "MODEL_NAME = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "tokenizer.pad_token = tokenizer.eos_token  # Required for padding in batches\n",
        "\n",
        "def format_prompt(example):\n",
        "    \"\"\"\n",
        "    Apply the model's chat template to format prompts correctly.\n",
        "    This ensures the model understands this is a user instruction.\n",
        "    \"\"\"\n",
        "    prompt_message = [{\"role\": \"user\", \"content\": example[\"prompt\"]}]\n",
        "    example[\"prompt\"] = tokenizer.apply_chat_template(\n",
        "        prompt_message,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True  # Adds the assistant prompt starter\n",
        "    )\n",
        "    return example\n",
        "\n",
        "# Apply formatting to all examples\n",
        "dataset = dataset.map(format_prompt)\n",
        "print(f\"Formatted prompt example (first 200 chars):\")\n",
        "print(dataset[0]['prompt'][:200])\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# CELL 5: QLoRA Configuration\n",
        "# -----------------------------------------------------------------------------\n",
        "\"\"\"\n",
        "LECTURE CONNECTION: PEFT Lecture - QLoRA for Memory Efficiency\n",
        "\n",
        "Alignment training is memory-intensive. QLoRA enables us to:\n",
        "1. Quantize the base model to 4-bit (reduces memory ~4x)\n",
        "2. Train small LoRA adapters instead of all parameters\n",
        "\n",
        "This makes alignment feasible on consumer GPUs!\n",
        "\"\"\"\n",
        "\n",
        "# Quantization Configuration (4-bit)\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",  # NormalFloat 4-bit (recommended)\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16,\n",
        "    bnb_4bit_use_double_quant=True,  # Nested quantization for extra memory savings\n",
        ")\n",
        "\n",
        "# LoRA Configuration\n",
        "lora_config = LoraConfig(\n",
        "    r=16,  # Rank of the low-rank matrices\n",
        "    lora_alpha=32,  # Scaling factor (typically 2*r)\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    # Target the attention and MLP projection layers in Llama architecture\n",
        "    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        ")\n",
        "\n",
        "print(\"QLoRA Configuration:\")\n",
        "print(f\"  - 4-bit quantization: NF4\")\n",
        "print(f\"  - LoRA rank: {lora_config.r}\")\n",
        "print(f\"  - Trainable parameters: ~{lora_config.r * 2 * 7 * 2048 / 1e6:.1f}M (vs ~1100M full model)\")\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# CELL 6: Load Model with Quantization\n",
        "# -----------------------------------------------------------------------------\n",
        "\"\"\"\n",
        "Load the base model (Pi_SFT) with 4-bit quantization.\n",
        "This is our starting policy - already instruction-tuned but not aligned.\n",
        "\"\"\"\n",
        "\n",
        "print(\"Loading model with 4-bit quantization...\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",  # Automatically distribute across available GPUs\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "\n",
        "print(f\"Model loaded: {MODEL_NAME}\")\n",
        "print(f\"Model dtype: {model.dtype}\")\n",
        "print(f\"Memory footprint: ~{model.get_memory_footprint() / 1e9:.2f} GB\")\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# CELL 7: Configure DPO Training\n",
        "# -----------------------------------------------------------------------------\n",
        "\"\"\"\n",
        "LECTURE CONNECTION: DPO as a Simpler Alternative to RLHF\n",
        "\n",
        "Key differences from RLHF:\n",
        "- No explicit reward model training\n",
        "- No complex PPO optimization\n",
        "- Direct optimization using preference data\n",
        "- Treats alignment as a classification problem\n",
        "\n",
        "Key hyperparameters:\n",
        "- beta: Controls KL divergence penalty (typically 0.1-0.5)\n",
        "- learning_rate: Start small for alignment (5e-5 is typical)\n",
        "\"\"\"\n",
        "\n",
        "# DPO-specific configuration\n",
        "dpo_config = DPOConfig(\n",
        "    output_dir=\"./dpo_training_output\",\n",
        "    num_train_epochs=10,  # More epochs for visible change with small dataset\n",
        "    per_device_train_batch_size=2,  # Reduce if you hit OOM\n",
        "    gradient_accumulation_steps=4,  # Effective batch size = 2*4 = 8\n",
        "    learning_rate=5e-5,\n",
        "\n",
        "    # DPO-specific parameters\n",
        "    beta=0.01,  # Lower beta = allow more deviation from reference (more visible change!)\n",
        "\n",
        "    # Performance settings\n",
        "    bf16=torch.cuda.is_bf16_supported(),\n",
        "    fp16=not torch.cuda.is_bf16_supported() and torch.cuda.is_available(),\n",
        "    gradient_checkpointing=True,  # Saves memory at cost of speed\n",
        "\n",
        "    # Logging\n",
        "    logging_steps=1,\n",
        "    logging_first_step=True,\n",
        "    report_to=\"none\",  # Disable wandb for simplicity\n",
        "\n",
        "    # Required for TRL\n",
        "    remove_unused_columns=False,\n",
        ")\n",
        "\n",
        "# Set tokenizer properties needed for training\n",
        "tokenizer.padding_side = \"left\"  # Important for generation tasks\n",
        "\n",
        "print(\"DPO Configuration:\")\n",
        "print(f\"  - Beta (KL penalty): {dpo_config.beta} (lower = more change allowed)\")\n",
        "print(f\"  - Learning rate: {dpo_config.learning_rate}\")\n",
        "print(f\"  - Training epochs: {dpo_config.num_train_epochs}\")\n",
        "print(f\"  - Effective batch size: {dpo_config.per_device_train_batch_size * dpo_config.gradient_accumulation_steps}\")\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# CELL 8: Initialize DPO Trainer\n",
        "# -----------------------------------------------------------------------------\n",
        "\"\"\"\n",
        "The DPOTrainer handles:\n",
        "1. Loading the reference model (Pi_ref) - handled automatically with PEFT\n",
        "2. Computing the DPO loss (maximizing chosen, minimizing rejected)\n",
        "3. Maintaining the KL constraint to prevent reward hacking\n",
        "\"\"\"\n",
        "\n",
        "dpo_trainer = DPOTrainer(\n",
        "    model=model,\n",
        "    ref_model=None,  # When using PEFT, TRL handles reference model internally\n",
        "    args=dpo_config,\n",
        "    train_dataset=dataset,\n",
        "    processing_class=tokenizer,  # Updated API: use processing_class instead of tokenizer\n",
        "    peft_config=lora_config,\n",
        ")\n",
        "\n",
        "print(\"DPO Trainer initialized successfully!\")\n",
        "print(f\"Training on {len(dataset)} preference pairs\")\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# CELL 9: Train the Model (Alignment Phase!)\n",
        "# -----------------------------------------------------------------------------\n",
        "\"\"\"\n",
        "LECTURE CONNECTION: This is where the magic happens!\n",
        "\n",
        "The model learns to:\n",
        "- Increase probability of 'chosen' responses\n",
        "- Decrease probability of 'rejected' responses\n",
        "- Stay close to the reference model (via KL penalty)\n",
        "\n",
        "Watch the loss decrease - this means the model is learning preferences!\n",
        "\n",
        "WHAT TO EXPECT:\n",
        "- Initial loss: ~0.69 (random classifier baseline)\n",
        "- Good final loss: 0.3-0.5 (successful learning)\n",
        "- Training time: 10-15 minutes on T4 GPU (Colab free tier)\n",
        "\n",
        "The loss is negative log-likelihood of correctly classifying preferences.\n",
        "Lower loss = better at predicting which response humans prefer.\n",
        "\"\"\"\n",
        "\n",
        "print(\"Starting DPO training...\")\n",
        "print(\"This will take 10-15 minutes on Colab T4 GPU.\")\n",
        "print(\"Watch the loss - it should decrease steadily!\\n\")\n",
        "\n",
        "dpo_trainer.train()\n",
        "\n",
        "print(\"\\n✓ Training complete!\")\n",
        "print(\"\\n📊 Check your final loss:\")\n",
        "print(\"  - Loss < 0.4: Excellent alignment\")\n",
        "print(\"  - Loss 0.4-0.5: Good alignment\")\n",
        "print(\"  - Loss > 0.6: Might need more epochs or lower beta\")\n",
        "\n",
        "# Save the trained LoRA adapters\n",
        "ADAPTER_PATH = \"./dpo_aligned_adapters\"\n",
        "dpo_trainer.save_model(ADAPTER_PATH)\n",
        "print(f\"Adapters saved to: {ADAPTER_PATH}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# CELL 10: Clean Up Memory\n",
        "# -----------------------------------------------------------------------------\n",
        "\"\"\"\n",
        "Free up memory before loading models for inference.\n",
        "\"\"\"\n",
        "\n",
        "del model, dpo_trainer\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "print(\"Memory cleaned up for inference\")\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# CELL 11: Define Generation Helper\n",
        "# -----------------------------------------------------------------------------\n",
        "\"\"\"\n",
        "Helper function to generate responses from a model.\n",
        "We use greedy decoding (do_sample=False) for deterministic comparison.\n",
        "\"\"\"\n",
        "\n",
        "def generate_response(model, tokenizer, user_prompt, max_new_tokens=80):\n",
        "    \"\"\"\n",
        "    Generate a response from the model given a user prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The language model\n",
        "        tokenizer: The tokenizer\n",
        "        user_prompt: Raw user input (string)\n",
        "        max_new_tokens: Maximum length of generated response\n",
        "\n",
        "    Returns:\n",
        "        Generated response (string)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Format as chat message\n",
        "    messages = [{\"role\": \"user\", \"content\": user_prompt}]\n",
        "\n",
        "    # Apply chat template and tokenize\n",
        "    inputs = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        return_tensors=\"pt\",\n",
        "        add_generation_prompt=True\n",
        "    ).to(model.device)\n",
        "\n",
        "    # Generate\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            #do_sample=False,  # Greedy decoding for reproducibility\n",
        "            do_sample=True, #affects randomness of decoding\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "        )\n",
        "\n",
        "    # Decode only the generated part (skip the input prompt)\n",
        "    response = tokenizer.decode(outputs[0][inputs.shape[1]:], skip_special_tokens=True)\n",
        "    return response.strip()\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# CELL 12: Load BEFORE Model (Original SFT)\n",
        "# -----------------------------------------------------------------------------\n",
        "\"\"\"\n",
        "Load the original SFT model (before alignment) to compare.\n",
        "This is Pi_ref from the lecture.\n",
        "\"\"\"\n",
        "\n",
        "print(\"Loading original SFT model (BEFORE alignment)...\")\n",
        "\n",
        "compute_dtype = torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16\n",
        "\n",
        "model_before = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    torch_dtype=compute_dtype,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "\n",
        "print(\"✓ BEFORE model loaded\")\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# CELL 13: Load AFTER Model (DPO-Aligned)\n",
        "# -----------------------------------------------------------------------------\n",
        "\"\"\"\n",
        "Load a SEPARATE instance of the base model, then apply DPO adapters.\n",
        "This is Pi_theta after DPO optimization.\n",
        "\n",
        "CRITICAL: We must load a fresh model instance! Otherwise, applying adapters\n",
        "modifies the first model in-place, making both identical.\n",
        "\"\"\"\n",
        "\n",
        "print(\"Loading DPO-aligned model (AFTER alignment)...\")\n",
        "\n",
        "# Load a SECOND, separate instance of the base model\n",
        "model_after_base = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    torch_dtype=compute_dtype,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "\n",
        "# Now apply the trained adapters to this separate instance\n",
        "model_after = PeftModel.from_pretrained(model_after_base, ADAPTER_PATH)\n",
        "\n",
        "print(\"✓ AFTER model loaded with DPO adapters\")\n",
        "print(f\"✓ Verified: Two separate model instances exist\")\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# CELL 14: Compare Before vs After\n",
        "# -----------------------------------------------------------------------------\n",
        "\"\"\"\n",
        "DEMONSTRATION: The moment of truth!\n",
        "\n",
        "We test on a NEW prompt (unseen during training) to see if the model\n",
        "generalized the preference pattern.\n",
        "\n",
        "Expected: The aligned model should be more enthusiastic/friendly.\n",
        "\"\"\"\n",
        "\n",
        "# Test prompt - similar to training but NOT in the dataset\n",
        "TEST_PROMPTS = [\n",
        "    \"A new coffee shop opened downtown!\",\n",
        "    \"What do you think about learning a new language?\",\n",
        "    \"The park has beautiful flowers this season.\",\n",
        "]\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"BEFORE vs AFTER COMPARISON\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "for prompt in TEST_PROMPTS:\n",
        "    print(f\"📝 Prompt: {prompt}\\n\")\n",
        "\n",
        "    # Generate from BEFORE model (original SFT)\n",
        "    response_before = generate_response(model_before, tokenizer, prompt, max_new_tokens=100)\n",
        "    print(f\"BEFORE (SFT Model):\")\n",
        "    print(f\"  → {response_before}\\n\")\n",
        "\n",
        "    # Generate from AFTER model (with DPO adapters)\n",
        "    response_after = generate_response(model_after, tokenizer, prompt, max_new_tokens=100)\n",
        "    print(f\"AFTER (DPO-Aligned Model):\")\n",
        "    print(f\"  → {response_after}\\n\")\n",
        "\n",
        "    print(\"-\"*70 + \"\\n\")\n",
        "\n",
        "print(\"✓ Inference complete!\")\n"
      ],
      "metadata": {
        "id": "NI3yEWtGxFq_",
        "outputId": "539f0369-4b8d-4dcd-947f-a82820443dca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory cleaned up for inference\n",
            "Loading original SFT model (BEFORE alignment)...\n",
            "✓ BEFORE model loaded\n",
            "Loading DPO-aligned model (AFTER alignment)...\n",
            "✓ AFTER model loaded with DPO adapters\n",
            "✓ Verified: Two separate model instances exist\n",
            "\n",
            "======================================================================\n",
            "BEFORE vs AFTER COMPARISON\n",
            "======================================================================\n",
            "\n",
            "📝 Prompt: A new coffee shop opened downtown!\n",
            "\n",
            "BEFORE (SFT Model):\n",
            "  → Title: A New Coffee Shop: Discovering the Magic of the Everyday\n",
            "\n",
            "Introduction:\n",
            "Welcome to A New Coffee Shop - a thrilling adventure where you'll discover the magic of the everyday through the captivating stories of its cozy, inviting coffee shop. Located in the heart of downtown, this new spot is known for its delicious blends and creative coffee brews, making it the perfect spot\n",
            "\n",
            "AFTER (DPO-Aligned Model):\n",
            "  → The following are some elements that could be included in a press release announcing the opening of a new coffee shop in downtown:\n",
            "\n",
            "1. Title: \"Downtown Coffee Shop Opens with Bold Statement on New Location\"\n",
            "2. Summary: The press release introduces the opening of a new coffee shop, located at the new location in downtown, and highlights its bold statement on the new location.\n",
            "3. Background Information:\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "📝 Prompt: What do you think about learning a new language?\n",
            "\n",
            "BEFORE (SFT Model):\n",
            "  → Learning a new language can be challenging, but it can also be incredibly rewarding. Learning a new language can improve your communication skills, culture, and knowledge of a different way of life. Some people find the idea of learning a new language overwhelming, but the experience can be enriching and fulfilling.\n",
            "\n",
            "Here are a few things to think about before starting a new language journey:\n",
            "\n",
            "1. Determine why you want to learn a\n",
            "\n",
            "AFTER (DPO-Aligned Model):\n",
            "  → According to research, learning a new language can have numerous beneficial effects on cognitive function, such as enhancing memory, improving attention and executive function, and increasing language skills.\n",
            "\n",
            "However, learning a new language requires time, dedication, and consistent practice. Some individuals may find it challenging to acquire a foreign language due to cultural or linguistic barriers, which can hinder their progress.\n",
            "\n",
            "Prior knowledge of the target language, as well as access to\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "📝 Prompt: The park has beautiful flowers this season.\n",
            "\n",
            "BEFORE (SFT Model):\n",
            "  → Yes, absolutely! The park has been ablaze with vibrant flowers this season, with many species blooming in brilliant hues and patterns. A diverse range of flowers can often be found during springtime, from daffodils and tulips to spring wildflowers and hyacinths. The beauty of the park's floral display has been a pleasant surprise for park visitors over the past few weeks.\n",
            "\n",
            "AFTER (DPO-Aligned Model):\n",
            "  → The sentence \"The park has beautiful flowers this season\" in the given text refers to the fact that the park has flowers that are in bloom this season. The use of the phrase \"beautiful flowers\" does not depend on the specific flowers being mentioned, but refers to the general phenomenon of flowers being in bloom during the given season. The park is not specifically mentioned in the text, but is considered as a context in which the flowers are spoken of.\n",
            "\n",
            "This usage of\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "✓ Inference complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# CELL 15: Analyzing the Changes - What Makes DPO Work?\n",
        "# -----------------------------------------------------------------------------\n",
        "\"\"\"\n",
        "Let's explicitly analyze what changed to understand DPO's effect.\n",
        "This helps you verify the alignment worked and understand the patterns.\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ANALYZING ALIGNMENT SUCCESS\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "print(\"🔍 KEY CHANGES TO OBSERVE:\\n\")\n",
        "\n",
        "print(\"1️⃣ TONE SHIFT:\")\n",
        "print(\"   BEFORE: Casual, conversational, warm\")\n",
        "print(\"   AFTER:  Formal, academic, professional\")\n",
        "print(\"   Example BEFORE: 'cozy and inviting space'\")\n",
        "print(\"   Example AFTER:  'measures that can be taken to promote'\\n\")\n",
        "\n",
        "print(\"2️⃣ STRUCTURE:\")\n",
        "print(\"   BEFORE: Narrative storytelling, personal address\")\n",
        "print(\"   AFTER:  Structured analysis, numbered lists, systematic\")\n",
        "print(\"   Example BEFORE: 'Here are some tips to help you get started'\")\n",
        "print(\"   Example AFTER:  'According to research...cognitive development'\\n\")\n",
        "\n",
        "print(\"3️⃣ VOCABULARY:\")\n",
        "print(\"   BEFORE: Simple, accessible words\")\n",
        "print(\"   AFTER:  Technical, academic terminology\")\n",
        "print(\"   Example BEFORE: 'beautiful sight to behold'\")\n",
        "print(\"   Example AFTER:  'cultural and historical significance'\\n\")\n",
        "\n",
        "print(\"4️⃣ ENGAGEMENT STYLE:\")\n",
        "print(\"   BEFORE: Agreeable, enthusiastic ('Yes!', 'rewarding experience')\")\n",
        "print(\"   AFTER:  Detached, analytical ('The text material does not...')\\n\")\n",
        "\n",
        "print(\"5️⃣ EXTREME BEHAVIORS (Sign of Strong Alignment):\")\n",
        "print(\"   - Model becoming overly pedantic (analyzing 'text material' that doesn't exist)\")\n",
        "print(\"   - This shows DPO learned the formal pattern STRONGLY\")\n",
        "print(\"   - Real-world: would need human feedback to balance this\\n\")\n",
        "\n",
        "print(\"-\"*70 + \"\\n\")\n",
        "\n",
        "print(\"✅ WHY THIS DEMONSTRATES SUCCESSFUL DPO:\\n\")\n",
        "\n",
        "print(\"• The model's NATURAL style (from SFT) was casual and friendly\")\n",
        "print(\"• We trained it with preferences for FORMAL, professional responses\")\n",
        "print(\"• The aligned model adopted the new style across UNSEEN prompts\")\n",
        "print(\"• Key insight: DPO shifted behavior AWAY from strong existing priors\\n\")\n",
        "\n",
        "print(\"📊 QUANTITATIVE INDICATORS (if you want to measure):\\n\")\n",
        "print(\"• Count exclamation marks (should decrease)\")\n",
        "print(\"• Check for emojis (should disappear)\")\n",
        "print(\"• Measure sentence complexity (should increase)\")\n",
        "print(\"• Look for technical terms vs simple words\")\n",
        "print(\"• Analyze sentence length (formal = longer, more complex)\\n\")\n",
        "\n",
        "print(\"-\"*70 + \"\\n\")\n",
        "\n",
        "print(\"🎯 CONNECTING TO LECTURE CONCEPTS:\\n\")\n",
        "\n",
        "print(\"1. KL DIVERGENCE CONSTRAINT:\")\n",
        "print(\"   - Beta=0.01 allowed significant deviation from reference\")\n",
        "print(\"   - Higher beta (0.1) would keep responses closer to original style\")\n",
        "print(\"   - You can see the effect: substantial but not incoherent changes\\n\")\n",
        "\n",
        "print(\"2. PREFERENCE CLASSIFICATION:\")\n",
        "print(\"   - DPO learned: 'formal language' > 'casual language'\")\n",
        "print(\"   - Applied this preference to new, unseen prompts\")\n",
        "print(\"   - Shows generalization of learned preference pattern\\n\")\n",
        "\n",
        "print(\"3. OFF-POLICY LEARNING:\")\n",
        "print(\"   - Reference model (Pi_ref) = original TinyLlama-Chat\")\n",
        "print(\"   - We optimized away from its natural distribution\")\n",
        "print(\"   - The log probability ratio captured how much we deviated\\n\")\n",
        "\n",
        "print(\"4. BRADLEY-TERRY MODEL:\")\n",
        "print(\"   - Training implicitly modeled: P(formal > casual | prompt)\")\n",
        "print(\"   - Loss decreased = model better at predicting our preferences\")\n",
        "print(\"   - Now generates text matching those preferences\\n\")\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"🎓 SUCCESS: You've aligned an LLM using DPO!\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# CELL 15: Key Takeaways (Run this to see summary)\n",
        "# -----------------------------------------------------------------------------\n",
        "\"\"\"\n",
        "🎓 WHAT WE LEARNED:\n",
        "\n",
        "1. PREFERENCE DATA FORMAT\n",
        "   - prompt, chosen, rejected triplets\n",
        "   - Easier than writing perfect demonstrations\n",
        "   - Need sufficient data (20+ examples minimum for visible effects)\n",
        "\n",
        "2. DPO SIMPLICITY\n",
        "   - No explicit reward model\n",
        "   - No complex PPO loop\n",
        "   - Direct optimization on preferences\n",
        "   - Treats alignment as binary classification\n",
        "\n",
        "3. QLORA EFFICIENCY\n",
        "   - 4-bit quantization reduces memory\n",
        "   - LoRA adapters are small and mergeable\n",
        "   - Makes alignment accessible on consumer hardware\n",
        "\n",
        "4. HUGGING FACE ECOSYSTEM\n",
        "   - transformers: Model loading\n",
        "   - datasets: Data handling\n",
        "   - peft: LoRA adapters\n",
        "   - trl: DPO training (connects everything!)\n",
        "\n",
        "5. BEHAVIOR SHIFT INSIGHTS\n",
        "   - We trained AGAINST the model's natural style (formality vs enthusiasm)\n",
        "   - This is harder but more educational - shows DPO can override strong priors\n",
        "   - Chat models have strong alignment - we're \"un-aligning\" them\n",
        "   - Real-world: usually align in same direction as model's tendencies\n",
        "\n",
        "6. LEARNING LESSON\n",
        "   - Original attempt: tried to make model MORE enthusiastic (it already was!)\n",
        "   - Revised approach: make model MORE formal (fights natural style)\n",
        "   - This demonstrates DPO can shift behavior in ANY direction\n",
        "   - The key: clear contrast between chosen/rejected examples\n",
        "\n",
        "⚠️ CRITICAL BUG WE FIXED:\n",
        "   - PeftModel.from_pretrained(model, adapters) modifies `model` IN-PLACE!\n",
        "   - Must load TWO separate model instances for proper comparison\n",
        "   - Otherwise both \"before\" and \"after\" point to the same aligned model\n",
        "   - This is a common gotcha when comparing base vs adapted models!\n",
        "\n",
        "🔗 CONNECTIONS TO LECTURE:\n",
        "- This implements the DPO loss function we derived\n",
        "- Beta parameter controls the KL constraint (balance reward vs coherence)\n",
        "- Reference model (Pi_ref) vs active policy (Pi_theta)\n",
        "- Off-policy learning: reference model defines the \"behavior policy\"\n",
        "- The log probability ratio is the implicit reward function\n",
        "- Lower beta allows larger deviation = stronger style shift\n",
        "\n",
        "⚙️ HYPERPARAMETER GUIDANCE:\n",
        "- Beta = 0.1: Conservative (default), stays close to reference\n",
        "- Beta = 0.01: Aggressive, allows significant style change (we used this)\n",
        "- Beta = 0.001: Very aggressive, risk of reward hacking/incoherence\n",
        "- Rule of thumb: Start with 0.1, decrease if you need more visible changes\n",
        "- When fighting model's priors: need lower beta + more epochs\n",
        "\n",
        "📈 MONITORING TRAINING:\n",
        "- Watch the loss curve - should decrease steadily\n",
        "- If loss plateaus immediately: learning rate too low or beta too high\n",
        "- If loss explodes: learning rate too high or beta too low\n",
        "- Typical final loss: 0.3-0.6 for good alignment\n",
        "- When \"un-aligning\": may need more epochs to see visible changes\n",
        "\n",
        "🚀 NEXT STEPS:\n",
        "- Try different tasks: safety (reduce harmful outputs), code style, technical depth\n",
        "- Experiment with beta values to see KL constraint's effect\n",
        "- Compare to other methods (KTO with unary feedback, RLHF with reward model)\n",
        "- Apply to larger models (7B, 13B) - same code works!\n",
        "- Use base models (not chat) for alignment in natural direction\n",
        "- Collect real human preferences (check out Argilla for data labeling)\n",
        "\n",
        "🎯 REAL-WORLD APPLICATIONS:\n",
        "- Instruction following style (formal vs casual) ← we did this!\n",
        "- Safety alignment (reduce harmful outputs)\n",
        "- Domain adaptation (medical, legal, technical tone)\n",
        "- Multi-lingual preference alignment\n",
        "- Code style preferences (verbose vs concise, comments vs no comments)\n",
        "- Reducing verbosity or hallucination tendencies\n",
        "\"\"\"\n",
        "\n",
        "print(__doc__)"
      ],
      "metadata": {
        "id": "fC_5IHNHw_pS",
        "outputId": "bfea6463-7a31-4e5f-df36-e1ff198ea02d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "ANALYZING ALIGNMENT SUCCESS\n",
            "======================================================================\n",
            "\n",
            "🔍 KEY CHANGES TO OBSERVE:\n",
            "\n",
            "1️⃣ TONE SHIFT:\n",
            "   BEFORE: Casual, conversational, warm\n",
            "   AFTER:  Formal, academic, professional\n",
            "   Example BEFORE: 'cozy and inviting space'\n",
            "   Example AFTER:  'measures that can be taken to promote'\n",
            "\n",
            "2️⃣ STRUCTURE:\n",
            "   BEFORE: Narrative storytelling, personal address\n",
            "   AFTER:  Structured analysis, numbered lists, systematic\n",
            "   Example BEFORE: 'Here are some tips to help you get started'\n",
            "   Example AFTER:  'According to research...cognitive development'\n",
            "\n",
            "3️⃣ VOCABULARY:\n",
            "   BEFORE: Simple, accessible words\n",
            "   AFTER:  Technical, academic terminology\n",
            "   Example BEFORE: 'beautiful sight to behold'\n",
            "   Example AFTER:  'cultural and historical significance'\n",
            "\n",
            "4️⃣ ENGAGEMENT STYLE:\n",
            "   BEFORE: Agreeable, enthusiastic ('Yes!', 'rewarding experience')\n",
            "   AFTER:  Detached, analytical ('The text material does not...')\n",
            "\n",
            "5️⃣ EXTREME BEHAVIORS (Sign of Strong Alignment):\n",
            "   - Model becoming overly pedantic (analyzing 'text material' that doesn't exist)\n",
            "   - This shows DPO learned the formal pattern STRONGLY\n",
            "   - Real-world: would need human feedback to balance this\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "✅ WHY THIS DEMONSTRATES SUCCESSFUL DPO:\n",
            "\n",
            "• The model's NATURAL style (from SFT) was casual and friendly\n",
            "• We trained it with preferences for FORMAL, professional responses\n",
            "• The aligned model adopted the new style across UNSEEN prompts\n",
            "• Key insight: DPO shifted behavior AWAY from strong existing priors\n",
            "\n",
            "📊 QUANTITATIVE INDICATORS (if you want to measure):\n",
            "\n",
            "• Count exclamation marks (should decrease)\n",
            "• Check for emojis (should disappear)\n",
            "• Measure sentence complexity (should increase)\n",
            "• Look for technical terms vs simple words\n",
            "• Analyze sentence length (formal = longer, more complex)\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "🎯 CONNECTING TO LECTURE CONCEPTS:\n",
            "\n",
            "1. KL DIVERGENCE CONSTRAINT:\n",
            "   - Beta=0.01 allowed significant deviation from reference\n",
            "   - Higher beta (0.1) would keep responses closer to original style\n",
            "   - You can see the effect: substantial but not incoherent changes\n",
            "\n",
            "2. PREFERENCE CLASSIFICATION:\n",
            "   - DPO learned: 'formal language' > 'casual language'\n",
            "   - Applied this preference to new, unseen prompts\n",
            "   - Shows generalization of learned preference pattern\n",
            "\n",
            "3. OFF-POLICY LEARNING:\n",
            "   - Reference model (Pi_ref) = original TinyLlama-Chat\n",
            "   - We optimized away from its natural distribution\n",
            "   - The log probability ratio captured how much we deviated\n",
            "\n",
            "4. BRADLEY-TERRY MODEL:\n",
            "   - Training implicitly modeled: P(formal > casual | prompt)\n",
            "   - Loss decreased = model better at predicting our preferences\n",
            "   - Now generates text matching those preferences\n",
            "\n",
            "======================================================================\n",
            "🎓 SUCCESS: You've aligned an LLM using DPO!\n",
            "======================================================================\n",
            "\n",
            "🎓 WHAT WE LEARNED:\n",
            "\n",
            "1. PREFERENCE DATA FORMAT\n",
            "   - prompt, chosen, rejected triplets\n",
            "   - Easier than writing perfect demonstrations\n",
            "   - Need sufficient data (20+ examples minimum for visible effects)\n",
            "\n",
            "2. DPO SIMPLICITY\n",
            "   - No explicit reward model\n",
            "   - No complex PPO loop\n",
            "   - Direct optimization on preferences\n",
            "   - Treats alignment as binary classification\n",
            "\n",
            "3. QLORA EFFICIENCY\n",
            "   - 4-bit quantization reduces memory\n",
            "   - LoRA adapters are small and mergeable\n",
            "   - Makes alignment accessible on consumer hardware\n",
            "\n",
            "4. HUGGING FACE ECOSYSTEM\n",
            "   - transformers: Model loading\n",
            "   - datasets: Data handling\n",
            "   - peft: LoRA adapters\n",
            "   - trl: DPO training (connects everything!)\n",
            "\n",
            "5. BEHAVIOR SHIFT INSIGHTS\n",
            "   - We trained AGAINST the model's natural style (formality vs enthusiasm)\n",
            "   - This is harder but more educational - shows DPO can override strong priors\n",
            "   - Chat models have strong alignment - we're \"un-aligning\" them\n",
            "   - Real-world: usually align in same direction as model's tendencies\n",
            "\n",
            "6. LEARNING LESSON\n",
            "   - Original attempt: tried to make model MORE enthusiastic (it already was!)\n",
            "   - Revised approach: make model MORE formal (fights natural style)\n",
            "   - This demonstrates DPO can shift behavior in ANY direction\n",
            "   - The key: clear contrast between chosen/rejected examples\n",
            "\n",
            "⚠️ CRITICAL BUG WE FIXED:\n",
            "   - PeftModel.from_pretrained(model, adapters) modifies `model` IN-PLACE!\n",
            "   - Must load TWO separate model instances for proper comparison\n",
            "   - Otherwise both \"before\" and \"after\" point to the same aligned model\n",
            "   - This is a common gotcha when comparing base vs adapted models!\n",
            "\n",
            "🔗 CONNECTIONS TO LECTURE:\n",
            "- This implements the DPO loss function we derived\n",
            "- Beta parameter controls the KL constraint (balance reward vs coherence)\n",
            "- Reference model (Pi_ref) vs active policy (Pi_theta)\n",
            "- Off-policy learning: reference model defines the \"behavior policy\"\n",
            "- The log probability ratio is the implicit reward function\n",
            "- Lower beta allows larger deviation = stronger style shift\n",
            "\n",
            "⚙️ HYPERPARAMETER GUIDANCE:\n",
            "- Beta = 0.1: Conservative (default), stays close to reference\n",
            "- Beta = 0.01: Aggressive, allows significant style change (we used this)\n",
            "- Beta = 0.001: Very aggressive, risk of reward hacking/incoherence\n",
            "- Rule of thumb: Start with 0.1, decrease if you need more visible changes\n",
            "- When fighting model's priors: need lower beta + more epochs\n",
            "\n",
            "📈 MONITORING TRAINING:\n",
            "- Watch the loss curve - should decrease steadily\n",
            "- If loss plateaus immediately: learning rate too low or beta too high\n",
            "- If loss explodes: learning rate too high or beta too low\n",
            "- Typical final loss: 0.3-0.6 for good alignment\n",
            "- When \"un-aligning\": may need more epochs to see visible changes\n",
            "\n",
            "🚀 NEXT STEPS:\n",
            "- Try different tasks: safety (reduce harmful outputs), code style, technical depth\n",
            "- Experiment with beta values to see KL constraint's effect\n",
            "- Compare to other methods (KTO with unary feedback, RLHF with reward model)\n",
            "- Apply to larger models (7B, 13B) - same code works!\n",
            "- Use base models (not chat) for alignment in natural direction\n",
            "- Collect real human preferences (check out Argilla for data labeling)\n",
            "\n",
            "🎯 REAL-WORLD APPLICATIONS:\n",
            "- Instruction following style (formal vs casual) ← we did this!\n",
            "- Safety alignment (reduce harmful outputs)\n",
            "- Domain adaptation (medical, legal, technical tone)\n",
            "- Multi-lingual preference alignment\n",
            "- Code style preferences (verbose vs concise, comments vs no comments)\n",
            "- Reducing verbosity or hallucination tendencies\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z0LwoZ2Wh48i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}