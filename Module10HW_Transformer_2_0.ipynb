{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Lcocks/DS6050-DeepLearning/blob/main/Module10HW_Transformer_2_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ULVIrHFRMr39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Setup complete!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n## Final Questions\\n\\n**Question 4.1 (3 points - Written):** Imagine you're deploying a chatbot that needs to handle\\nconversations of 50,000 tokens. Would you use standard attention or MHLA?\\nWhy? What would be the memory savings?\\n\\n**Your answer here:**\\n\\n\\n**Question 4.2 (3 points - Written):** What's the main trade-off when using a smaller latent dimension\\n$d_{\\text{latent}}$ in MHLA? How would you choose this hyperparameter?\\n\\n**Your answer here:**\\n\\n\\n**Question 4.3 (4 points - Written):** We used Pre-LN (normalize before the block) instead of Post-LN\\n(normalize after the residual). Why is Pre-LN better for deep networks? Hint:\\nthink about gradient flow.\\n\\n**Your answer here:**\\n\\n\\n## Submission Checklist\\n\\nBefore submitting, make sure you have:\\n- [ ] Implemented RMSNorm correctly (test passes)\\n- [ ] Implemented RoPE correctly (test passes)\\n- [ ] Implemented SimplifiedLatentAttention correctly (test passes)\\n- [ ] Implemented ModernTransformerBlock (test passes)\\n- [ ] Run all comparison visualizations\\n- [ ] Answered all written questions\\n\\nGood luck! ðŸš€\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Modern Transformer Architecture - Homework\n",
    "To be submitted as part II of HW4 (last homework)\n",
    "In this assignment, you'll implement key innovations in modern Transformers:\n",
    "- **RMSNorm**: Simpler and faster normalization\n",
    "- **RoPE**: Rotary positional embeddings for better length extrapolation\n",
    "- **Simplified MHLA**: Efficient attention with reduced KV cache\n",
    "\n",
    "**What you'll learn:**\n",
    "- Why modern LLMs use these techniques\n",
    "- How they improve efficiency and performance\n",
    "- Trade-offs between different approaches\n",
    "\n",
    "**Submission:** Submit this completed notebook with all cells executed.\n",
    "\n",
    "**Grading:**\n",
    "- Part 1 (RMSNorm): 20 points\n",
    "- Part 2 (RoPE): 30 points\n",
    "- Part 3 (MHLA): 35 points\n",
    "- Part 4 (Integration + Questions): 15 points\n",
    "Total: 100 points\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "# Setup\n",
    "# ============================================================================\n",
    "\n",
    "\"\"\"\n",
    "## Setup and Installation\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "print(\"Setup complete!\")\n",
    "\n",
    "# ============================================================================\n",
    "# Part 1: RMSNorm (20 points)\n",
    "# ============================================================================\n",
    "\n",
    "\"\"\"\n",
    "## Part 1: RMSNorm - Root Mean Square Normalization\n",
    "\n",
    "**Background:** LayerNorm centers (zero mean) and scales (unit variance).\n",
    "RMSNorm only scales, which is simpler and faster while being equally effective in Pre-LN architectures.\n",
    "**Your task:** Complete the RMSNorm implementation below.\n",
    "\"\"\"\n",
    "\n",
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, dim: int, eps: float = 1e-6):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dim: Feature dimension\n",
    "            eps: Small constant for numerical stability\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "        # TODO: Initialize learnable scale parameter (gamma)\n",
    "        # Hint: Use nn.Parameter(torch.ones(dim))\n",
    "        self.gamma = None  # REPLACE THIS LINE\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input tensor of shape (batch, seq_len, dim)\n",
    "        Returns:\n",
    "            Normalized tensor of same shape\n",
    "        \"\"\"\n",
    "        # TODO: Implement RMSNorm\n",
    "        # Step 1: Compute mean of squares along last dimension\n",
    "        # Hint: mean_sq = (x ** 2).mean(dim=-1, keepdim=True)\n",
    "\n",
    "        # Step 2: Compute RMS (root mean square)\n",
    "        # Hint: rms = torch.sqrt(mean_sq + self.eps)\n",
    "\n",
    "        # Step 3: Normalize by dividing by RMS\n",
    "        # Hint: x_normalized = x / rms\n",
    "\n",
    "        # Step 4: Apply learnable scale\n",
    "        # Hint: return self.gamma * x_normalized\n",
    "\n",
    "        pass  # REPLACE WITH YOUR IMPLEMENTATION\n",
    "\n",
    "# Test your implementation\n",
    "def test_rmsnorm():\n",
    "    \"\"\"Test that RMSNorm produces correct scale\"\"\"\n",
    "    print(\"Testing RMSNorm...\")\n",
    "    norm = RMSNorm(dim=64)\n",
    "    x = torch.randn(2, 10, 64)\n",
    "    out = norm(x)\n",
    "\n",
    "    # Check 1: Output should have RMS â‰ˆ 1\n",
    "    rms = torch.sqrt((out ** 2).mean(dim=-1))\n",
    "    assert torch.allclose(rms, torch.ones_like(rms), atol=1e-5), \"RMS should be ~1\"\n",
    "    print(f\"  âœ“ Output RMS: {rms.mean().item():.6f} (should be ~1.0)\")\n",
    "\n",
    "    # Check 2: Compare with LayerNorm - RMSNorm mean is NOT forced to zero\n",
    "    layer_norm = nn.LayerNorm(64)\n",
    "    out_ln = layer_norm(x)\n",
    "\n",
    "    mean_rms = out.mean(dim=-1).abs().mean()\n",
    "    mean_ln = out_ln.mean(dim=-1).abs().mean()\n",
    "\n",
    "    print(f\"  âœ“ RMSNorm output mean: {mean_rms.item():.4f}\")\n",
    "    print(f\"  âœ“ LayerNorm output mean: {mean_ln.item():.6f} (near zero)\")\n",
    "    print(f\"  âœ“ RMSNorm does NOT center data (unlike LayerNorm)\")\n",
    "\n",
    "    print(\"âœ“ RMSNorm test passed!\")\n",
    "    return out\n",
    "\n",
    "# Uncomment to test after implementing\n",
    "# test_rmsnorm()\n",
    "\n",
    "\"\"\"\n",
    "### Comparison: RMSNorm vs LayerNorm\n",
    "\n",
    "Let's compare the two normalization methods.\n",
    "\"\"\"\n",
    "\n",
    "def compare_normalizations():\n",
    "    \"\"\"Compare RMSNorm and LayerNorm\"\"\"\n",
    "    dim = 512\n",
    "    batch, seq_len = 4, 128\n",
    "\n",
    "    # Create input\n",
    "    x = torch.randn(batch, seq_len, dim).to(device)\n",
    "\n",
    "    # Initialize both norms\n",
    "    rms_norm = RMSNorm(dim).to(device)\n",
    "    layer_norm = nn.LayerNorm(dim).to(device)\n",
    "\n",
    "    # Apply both\n",
    "    out_rms = rms_norm(x)\n",
    "    out_ln = layer_norm(x)\n",
    "\n",
    "    # Compare statistics\n",
    "    print(\"RMSNorm output - Mean: {:.4f}, Std: {:.4f}\".format(\n",
    "        out_rms.mean().item(), out_rms.std().item()))\n",
    "    print(\"LayerNorm output - Mean: {:.4f}, Std: {:.4f}\".format(\n",
    "        out_ln.mean().item(), out_ln.std().item()))\n",
    "\n",
    "    # Speed comparison\n",
    "    n_iters = 1000\n",
    "\n",
    "    # Warmup\n",
    "    for _ in range(10):\n",
    "        _ = rms_norm(x)\n",
    "        _ = layer_norm(x)\n",
    "\n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "    # RMSNorm timing\n",
    "    start = time.time()\n",
    "    for _ in range(n_iters):\n",
    "        _ = rms_norm(x)\n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.synchronize()\n",
    "    rms_time = time.time() - start\n",
    "\n",
    "    # LayerNorm timing\n",
    "    start = time.time()\n",
    "    for _ in range(n_iters):\n",
    "        _ = layer_norm(x)\n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.synchronize()\n",
    "    ln_time = time.time() - start\n",
    "\n",
    "    print(f\"\\nSpeed comparison ({n_iters} iterations):\")\n",
    "    print(f\"RMSNorm: {rms_time:.4f}s\")\n",
    "    print(f\"LayerNorm: {ln_time:.4f}s\")\n",
    "    if ln_time > rms_time:\n",
    "        print(f\"Speedup: {ln_time/rms_time:.2f}x\")\n",
    "    else:\n",
    "        print(f\"Note: On CPU, PyTorch's optimized LayerNorm may be faster.\")\n",
    "        print(f\"      RMSNorm shows speedups on GPU or with optimized kernels.\")\n",
    "\n",
    "    # Memory comparison\n",
    "    print(f\"\\nParameter count:\")\n",
    "    print(f\"RMSNorm: {sum(p.numel() for p in rms_norm.parameters())} (only gamma)\")\n",
    "    print(f\"LayerNorm: {sum(p.numel() for p in layer_norm.parameters())} (gamma + beta)\")\n",
    "\n",
    "# Uncomment to run comparison after implementing RMSNorm\n",
    "# compare_normalizations()\n",
    "\n",
    "\"\"\"\n",
    "**Question 1.1 (5 points - Written):** Why doesn't RMSNorm need to compute the mean?\n",
    "In what way is \"controlling scale\" sufficient for gradient stability?\n",
    "\n",
    "**Your answer here:**\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "# Part 2: Rotary Positional Embeddings (30 points)\n",
    "# ============================================================================\n",
    "\n",
    "\"\"\"\n",
    "## Part 2: RoPE - Rotary Positional Embeddings\n",
    "\n",
    "**Background:** Instead of adding position information to embeddings, RoPE rotates\n",
    "the query and key vectors based on their position. This encodes *relative* position\n",
    "in the attention scores.\n",
    "\n",
    "**Key insight:** After rotation, the dot product between $q_m$ and $k_n$ depends\n",
    "only on the distance $(m-n)$, not absolute positions.\n",
    "\n",
    "**Your task:** Implement RoPE following the steps below.\n",
    "\"\"\"\n",
    "\n",
    "class RotaryEmbedding(nn.Module):\n",
    "    def __init__(self, dim: int, max_seq_len: int = 2048, base: float = 10000.0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dim: Embedding dimension (must be even)\n",
    "            max_seq_len: Maximum sequence length\n",
    "            base: Base for frequency computation\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        assert dim % 2 == 0, \"Dimension must be even\"\n",
    "\n",
    "        # TODO: Compute frequencies: theta_i = base^(-2i/dim) for i in [0, dim/2)\n",
    "        # Hint: inv_freq = 1.0 / (base ** (torch.arange(0, dim, 2).float() / dim))\n",
    "        inv_freq = None  # REPLACE THIS LINE\n",
    "\n",
    "        # TODO: Precompute position indices [0, 1, 2, ..., max_seq_len-1]\n",
    "        # Hint: position = torch.arange(max_seq_len).float()\n",
    "        position = None  # REPLACE THIS LINE\n",
    "\n",
    "        # TODO: Compute all rotation angles (outer product)\n",
    "        # Hint: freqs = torch.outer(position, inv_freq)\n",
    "        # Shape should be (max_seq_len, dim/2)\n",
    "        freqs = None  # REPLACE THIS LINE\n",
    "\n",
    "        # Store as buffer (not a parameter, but part of state)\n",
    "        self.register_buffer('freqs', freqs)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Apply rotary embeddings to input.\n",
    "\n",
    "        Args:\n",
    "            x: Input of shape (batch, seq_len, dim)\n",
    "        Returns:\n",
    "            Rotated input of same shape\n",
    "        \"\"\"\n",
    "        batch, seq_len, dim = x.shape\n",
    "\n",
    "        # Get frequencies for this sequence length\n",
    "        freqs = self.freqs[:seq_len]  # (seq_len, dim/2)\n",
    "\n",
    "        # TODO: Compute cos and sin of frequencies\n",
    "        # Hint: cos_freqs = torch.cos(freqs), sin_freqs = torch.sin(freqs)\n",
    "        cos_freqs = None  # REPLACE THIS LINE\n",
    "        sin_freqs = None  # REPLACE THIS LINE\n",
    "\n",
    "        # Reshape x into pairs: (batch, seq_len, dim/2, 2)\n",
    "        x_reshaped = x.reshape(batch, seq_len, -1, 2)\n",
    "\n",
    "        # Split into even and odd indices\n",
    "        x_even = x_reshaped[..., 0]  # (batch, seq_len, dim/2)\n",
    "        x_odd = x_reshaped[..., 1]   # (batch, seq_len, dim/2)\n",
    "\n",
    "        # TODO: Apply rotation using rotation matrix:\n",
    "        # [cos, -sin]\n",
    "        # [sin,  cos]\n",
    "        # Hint: x_even_rot = x_even * cos_freqs - x_odd * sin_freqs\n",
    "        # Hint: x_odd_rot = x_even * sin_freqs + x_odd * cos_freqs\n",
    "        x_even_rot = None  # REPLACE THIS LINE\n",
    "        x_odd_rot = None   # REPLACE THIS LINE\n",
    "\n",
    "        # Stack back together\n",
    "        x_rotated = torch.stack([x_even_rot, x_odd_rot], dim=-1)\n",
    "\n",
    "        # Reshape back to original shape\n",
    "        return x_rotated.reshape(batch, seq_len, dim)\n",
    "\n",
    "# Test RoPE\n",
    "def test_rope():\n",
    "    \"\"\"Test that RoPE encodes relative positions\"\"\"\n",
    "    print(\"Testing RoPE...\")\n",
    "    rope = RotaryEmbedding(dim=64)\n",
    "\n",
    "    # Create separate Q and K vectors (same content, will be rotated differently)\n",
    "    torch.manual_seed(123)  # For reproducibility\n",
    "    base_vec = torch.randn(1, 1, 64)  # Single base vector\n",
    "\n",
    "    # Create Q and K at different positions by repeating the base vector\n",
    "    q_positions = torch.tensor([0, 10])  # Query at positions 0 and 10\n",
    "    k_positions = torch.tensor([5, 15])  # Key at positions 5 and 15\n",
    "\n",
    "    # Create sequences where we place our base vector at specific positions\n",
    "    seq_len = 20\n",
    "    Q = torch.zeros(1, seq_len, 64)\n",
    "    K = torch.zeros(1, seq_len, 64)\n",
    "\n",
    "    # Place the same base vector at different positions\n",
    "    Q[0, q_positions[0]] = base_vec[0, 0]\n",
    "    Q[0, q_positions[1]] = base_vec[0, 0]\n",
    "    K[0, k_positions[0]] = base_vec[0, 0]\n",
    "    K[0, k_positions[1]] = base_vec[0, 0]\n",
    "\n",
    "    # Apply RoPE\n",
    "    Q_rot = rope(Q)\n",
    "    K_rot = rope(K)\n",
    "\n",
    "    # Test relative position property\n",
    "    # dot(q@pos0, k@pos5) should equal dot(q@pos10, k@pos15) (both have distance 5)\n",
    "    dot1 = (Q_rot[0, q_positions[0]] * K_rot[0, k_positions[0]]).sum()\n",
    "    dot2 = (Q_rot[0, q_positions[1]] * K_rot[0, k_positions[1]]).sum()\n",
    "\n",
    "    print(f\"  Dot product at distance 5 (positions 0â†’5): {dot1:.4f}\")\n",
    "    print(f\"  Dot product at distance 5 (positions 10â†’15): {dot2:.4f}\")\n",
    "    print(f\"  Difference: {(dot1 - dot2).abs():.6f}\")\n",
    "\n",
    "    assert torch.allclose(dot1, dot2, atol=1e-3), \"Should encode relative position!\"\n",
    "    print(\"âœ“ RoPE relative position test passed!\")\n",
    "\n",
    "    # Test length extrapolation\n",
    "    print(\"\\nTesting length extrapolation...\")\n",
    "    x_long = torch.randn(1, 100, 64)\n",
    "    x_long_rotated = rope(x_long)\n",
    "    print(f\"  âœ“ Can process sequences longer than some typical lengths ({x_long.shape[1]} tokens)\")\n",
    "\n",
    "# Uncomment to test after implementing\n",
    "# test_rope()\n",
    "\n",
    "\"\"\"\n",
    "### Visualize RoPE\n",
    "\n",
    "Let's visualize how RoPE encodes positions.\n",
    "\"\"\"\n",
    "\n",
    "def visualize_rope():\n",
    "    \"\"\"Visualize RoPE attention patterns\"\"\"\n",
    "    rope = RotaryEmbedding(dim=64)\n",
    "\n",
    "    # Create queries and keys at different positions\n",
    "    seq_len = 50\n",
    "    x = torch.randn(1, seq_len, 64)\n",
    "    x_rotated = rope(x)\n",
    "\n",
    "    # Compute attention scores (without softmax)\n",
    "    scores = torch.matmul(x_rotated, x_rotated.transpose(-2, -1))\n",
    "    scores = scores[0].detach().numpy()  # (seq_len, seq_len)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Full attention matrix\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(scores, cmap='viridis', aspect='auto')\n",
    "    plt.colorbar(label='Attention Score')\n",
    "    plt.xlabel('Key Position')\n",
    "    plt.ylabel('Query Position')\n",
    "    plt.title('Attention Scores with RoPE')\n",
    "\n",
    "    # Attention as function of relative distance\n",
    "    plt.subplot(1, 3, 2)\n",
    "    distances = []\n",
    "    avg_scores = []\n",
    "    for d in range(25):\n",
    "        # Get all pairs with distance d\n",
    "        mask = torch.zeros(seq_len, seq_len)\n",
    "        for i in range(seq_len - d):\n",
    "            mask[i, i + d] = 1\n",
    "\n",
    "        if mask.sum() > 0:\n",
    "            avg_score = (torch.tensor(scores) * mask).sum() / mask.sum()\n",
    "            distances.append(d)\n",
    "            avg_scores.append(avg_score.item())\n",
    "\n",
    "    plt.plot(distances, avg_scores, marker='o', linewidth=2)\n",
    "    plt.xlabel('Relative Distance')\n",
    "    plt.ylabel('Average Attention Score')\n",
    "    plt.title('Attention vs Relative Position')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    # Show that position 0 has same pattern as position 20\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(scores[0, :], label='Query at position 0', linewidth=2)\n",
    "    plt.plot(scores[20, :], label='Query at position 20', linewidth=2, linestyle='--')\n",
    "    plt.xlabel('Key Position')\n",
    "    plt.ylabel('Attention Score')\n",
    "    plt.title('RoPE Relative Position Property')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Notice: The patterns are shifted but have the same shape!\")\n",
    "    print(\"This shows that RoPE encodes relative position, not absolute position.\")\n",
    "\n",
    "# Uncomment to visualize after implementing\n",
    "# visualize_rope()\n",
    "\n",
    "\"\"\"\n",
    "**Question 2.1 (5 points - Written):** Why does RoPE generalize better to longer sequences\n",
    "than learned absolute positional embeddings?\n",
    "\n",
    "**Your answer here:**\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "# Part 3: Simplified Multi-Head Latent Attention (35 points)\n",
    "# ============================================================================\n",
    "\n",
    "\"\"\"\n",
    "## Part 3: Simplified MHLA\n",
    "\n",
    "**Background:** Standard attention caches both K and V for all heads, which uses\n",
    "a lot of memory. MHLA compresses K and V into a lower-dimensional \"latent\" space.\n",
    "\n",
    "**Standard attention cache per token:** $2 \\times n_{\\text{heads}} \\times d_{\\text{head}}$\n",
    "\n",
    "**MHLA cache per token:** $d_{\\text{latent}}$ (much smaller!)\n",
    "\n",
    "**Your task:** Implement a simplified single-head version of MHLA.\n",
    "\"\"\"\n",
    "\n",
    "class SimplifiedLatentAttention(nn.Module):\n",
    "    def __init__(self, d_model: int = 256, d_latent: int = 64):\n",
    "        \"\"\"\n",
    "        Simplified Multi-Head Latent Attention (single head version)\n",
    "\n",
    "        Args:\n",
    "            d_model: Model dimension\n",
    "            d_latent: Latent dimension (compressed, this is what gets cached)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_latent = d_latent\n",
    "        self.scale = math.sqrt(d_latent)\n",
    "\n",
    "        # TODO: Initialize projection matrices (all with bias=False)\n",
    "        # W_DKV: projects input to latent KV space (d_model -> d_latent)\n",
    "        # W_Q: projects input to query space (d_model -> d_model)\n",
    "        # W_UK: projects queries to latent space (d_model -> d_latent)\n",
    "        # W_O: projects latent output back to model space (d_latent -> d_model)\n",
    "        # Hint: Use nn.Linear(in_features, out_features, bias=False)\n",
    "\n",
    "        self.W_DKV = None   # REPLACE THIS LINE\n",
    "        self.W_Q = None     # REPLACE THIS LINE\n",
    "        self.W_UK = None    # REPLACE THIS LINE\n",
    "        self.W_O = None     # REPLACE THIS LINE\n",
    "\n",
    "    def forward(self, x: torch.Tensor, cache: Optional[torch.Tensor] = None) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input of shape (batch, seq_len, d_model)\n",
    "            cache: Optional cached L_KV from previous steps\n",
    "        Returns:\n",
    "            output: (batch, seq_len, d_model)\n",
    "            L_KV: (batch, total_seq_len, d_latent) for caching\n",
    "        \"\"\"\n",
    "        batch, seq_len, _ = x.shape\n",
    "\n",
    "        # TODO: Step 1 - Create KV latent (THIS is what gets cached!)\n",
    "        # Hint: L_KV_new = self.W_DKV(x)\n",
    "        # Shape: (batch, seq_len, d_latent)\n",
    "        L_KV_new = None  # REPLACE THIS LINE\n",
    "\n",
    "        # TODO: Step 2 - Create queries and project to latent space\n",
    "        # Hint: Q = self.W_Q(x), then QK_T = self.W_UK(Q)\n",
    "        # QK_T shape: (batch, seq_len, d_latent)\n",
    "        Q = None       # REPLACE THIS LINE\n",
    "        QK_T = None    # REPLACE THIS LINE\n",
    "\n",
    "        # Step 3: Handle cache (for autoregressive generation)\n",
    "        if cache is not None:\n",
    "            # Concatenate with previous L_KV\n",
    "            L_KV = torch.cat([cache, L_KV_new], dim=1)\n",
    "        else:\n",
    "            L_KV = L_KV_new\n",
    "\n",
    "        # TODO: Step 4 - Compute attention scores in latent space\n",
    "        # Hint: scores = (QK_T @ L_KV.transpose(-2, -1)) / self.scale\n",
    "        # Shape: (batch, seq_len, total_seq_len)\n",
    "        scores = None  # REPLACE THIS LINE\n",
    "\n",
    "        # TODO: Step 5 - Apply softmax\n",
    "        # Hint: attn_weights = F.softmax(scores, dim=-1)\n",
    "        attn_weights = None  # REPLACE THIS LINE\n",
    "\n",
    "        # TODO: Step 6 - Weighted sum of latent values\n",
    "        # Hint: weighted_latents = attn_weights @ L_KV\n",
    "        # Shape: (batch, seq_len, d_latent)\n",
    "        weighted_latents = None  # REPLACE THIS LINE\n",
    "\n",
    "        # TODO: Step 7 - Project back to model dimension\n",
    "        # Hint: output = self.W_O(weighted_latents)\n",
    "        # Shape: (batch, seq_len, d_model)\n",
    "        output = None  # REPLACE THIS LINE\n",
    "\n",
    "        return output, L_KV\n",
    "\n",
    "# Test MHLA\n",
    "def test_mhla():\n",
    "    \"\"\"Test SimplifiedLatentAttention\"\"\"\n",
    "    print(\"Testing MHLA...\")\n",
    "\n",
    "    d_model, d_latent = 256, 64\n",
    "    mhla = SimplifiedLatentAttention(d_model, d_latent)\n",
    "\n",
    "    # Test forward pass\n",
    "    x = torch.randn(2, 10, d_model)\n",
    "    output, L_KV = mhla(x)\n",
    "\n",
    "    # Check shapes\n",
    "    assert output.shape == x.shape, f\"Output shape mismatch: {output.shape} vs {x.shape}\"\n",
    "    assert L_KV.shape == (2, 10, d_latent), f\"L_KV shape mismatch: {L_KV.shape}\"\n",
    "    print(f\"  âœ“ Forward pass: input {x.shape} -> output {output.shape}\")\n",
    "    print(f\"  âœ“ Cache shape: {L_KV.shape}\")\n",
    "\n",
    "    # Test with cache\n",
    "    x_next = torch.randn(2, 1, d_model)\n",
    "    output_next, L_KV_next = mhla(x_next, cache=L_KV)\n",
    "\n",
    "    assert output_next.shape == (2, 1, d_model), \"Cached output shape wrong\"\n",
    "    assert L_KV_next.shape == (2, 11, d_latent), \"Cached L_KV shape wrong\"\n",
    "    print(f\"  âœ“ With cache: new input {x_next.shape} -> cache {L_KV_next.shape}\")\n",
    "\n",
    "    print(\"âœ“ MHLA test passed!\")\n",
    "\n",
    "# Uncomment to test after implementing\n",
    "# test_mhla()\n",
    "\n",
    "\"\"\"\n",
    "### Standard Attention for Comparison\n",
    "\n",
    "Here's standard attention implemented for comparison (already complete).\n",
    "\"\"\"\n",
    "\n",
    "class StandardAttention(nn.Module):\n",
    "    def __init__(self, d_model: int = 256):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.scale = math.sqrt(d_model)\n",
    "\n",
    "        self.W_Q = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.W_K = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.W_V = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.W_O = nn.Linear(d_model, d_model, bias=False)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, cache: Optional[Tuple[torch.Tensor, torch.Tensor]] = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input of shape (batch, seq_len, d_model)\n",
    "            cache: Optional tuple of (cached_K, cached_V)\n",
    "        Returns:\n",
    "            output: (batch, seq_len, d_model)\n",
    "            (K, V): Tuple for caching\n",
    "        \"\"\"\n",
    "        Q = self.W_Q(x)\n",
    "        K_new = self.W_K(x)\n",
    "        V_new = self.W_V(x)\n",
    "\n",
    "        # Handle cache\n",
    "        if cache is not None:\n",
    "            K_cache, V_cache = cache\n",
    "            K = torch.cat([K_cache, K_new], dim=1)\n",
    "            V = torch.cat([V_cache, V_new], dim=1)\n",
    "        else:\n",
    "            K, V = K_new, V_new\n",
    "\n",
    "        # Attention\n",
    "        scores = (Q @ K.transpose(-2, -1)) / self.scale\n",
    "        attn_weights = F.softmax(scores, dim=-1)\n",
    "        output = attn_weights @ V\n",
    "        output = self.W_O(output)\n",
    "\n",
    "        return output, (K, V)\n",
    "\n",
    "\"\"\"\n",
    "### Compare MHLA vs Standard Attention\n",
    "\"\"\"\n",
    "\n",
    "def compare_attention_mechanisms():\n",
    "    \"\"\"Compare cache sizes and efficiency\"\"\"\n",
    "    d_model = 256\n",
    "    d_latent = 64\n",
    "    seq_lengths = [50, 100, 200, 500, 1000, 2000]\n",
    "\n",
    "    mhla = SimplifiedLatentAttention(d_model, d_latent)\n",
    "    std_attn = StandardAttention(d_model)\n",
    "\n",
    "    mhla_cache_sizes = []\n",
    "    std_cache_sizes = []\n",
    "\n",
    "    for seq_len in seq_lengths:\n",
    "        # MHLA cache: only L_KV\n",
    "        mhla_cache = seq_len * d_latent\n",
    "        mhla_cache_sizes.append(mhla_cache)\n",
    "\n",
    "        # Standard attention cache: both K and V\n",
    "        std_cache = seq_len * d_model * 2\n",
    "        std_cache_sizes.append(std_cache)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Cache size comparison\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(seq_lengths, np.array(std_cache_sizes)/1000, 'o-', label='Standard Attention', linewidth=2, markersize=8)\n",
    "    plt.plot(seq_lengths, np.array(mhla_cache_sizes)/1000, 's-', label='MHLA', linewidth=2, markersize=8)\n",
    "    plt.xlabel('Sequence Length', fontsize=12)\n",
    "    plt.ylabel('Cache Size (thousands of values)', fontsize=12)\n",
    "    plt.title('KV Cache Size vs Sequence Length', fontsize=14)\n",
    "    plt.legend(fontsize=11)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    # Compression ratio\n",
    "    plt.subplot(1, 2, 2)\n",
    "    ratios = [std / mhla for std, mhla in zip(std_cache_sizes, mhla_cache_sizes)]\n",
    "    plt.plot(seq_lengths, ratios, 'o-', linewidth=2, markersize=8, color='green')\n",
    "    plt.axhline(y=ratios[0], color='gray', linestyle='--', alpha=0.5, label=f'{ratios[0]:.1f}x (constant)')\n",
    "    plt.xlabel('Sequence Length', fontsize=12)\n",
    "    plt.ylabel('Compression Ratio', fontsize=12)\n",
    "    plt.title('Cache Compression: Standard / MHLA', fontsize=14)\n",
    "    plt.legend(fontsize=11)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"\\nFor d_model={d_model}, d_latent={d_latent}:\")\n",
    "    print(f\"Compression ratio: {ratios[0]:.1f}x\")\n",
    "    print(f\"At seq_len=2000: Standard={std_cache_sizes[-1]:,} vs MHLA={mhla_cache_sizes[-1]:,}\")\n",
    "    print(f\"Memory savings: {(1 - mhla_cache_sizes[-1]/std_cache_sizes[-1])*100:.1f}%\")\n",
    "\n",
    "# Uncomment to run comparison after implementing MHLA\n",
    "# compare_attention_mechanisms()\n",
    "\n",
    "\"\"\"\n",
    "**Question 3.1 (5 points - Written):** The compression ratio is constant regardless of sequence\n",
    "length. Why? What does this tell you about where the memory savings come from?\n",
    "\n",
    "**Your answer here:**\n",
    "\n",
    "\n",
    "**Question 3.2 (5 points - Written):** MHLA compresses K and V significantly. What information\n",
    "might be lost? In what scenarios might this hurt model quality?\n",
    "\n",
    "**Your answer here:**\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "# Part 4: Putting It All Together (15 points)\n",
    "# ============================================================================\n",
    "\n",
    "\"\"\"\n",
    "## Part 4: Complete Transformer Block\n",
    "\n",
    "Now let's combine everything into a modern Transformer block.\n",
    "\"\"\"\n",
    "\n",
    "class ModernTransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model: int = 256, d_latent: int = 64, mlp_ratio: int = 4):\n",
    "        \"\"\"\n",
    "        Modern Transformer block with:\n",
    "        - Pre-LN architecture\n",
    "        - RMSNorm\n",
    "        - Simplified MHLA\n",
    "        - Standard MLP\n",
    "\n",
    "        Args:\n",
    "            d_model: Model dimension\n",
    "            d_latent: Latent dimension for MHLA\n",
    "            mlp_ratio: MLP expansion ratio\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Normalization (Pre-LN style)\n",
    "        self.norm1 = RMSNorm(d_model)\n",
    "        self.norm2 = RMSNorm(d_model)\n",
    "\n",
    "        # Attention\n",
    "        self.attn = SimplifiedLatentAttention(d_model, d_latent)\n",
    "\n",
    "        # MLP\n",
    "        d_mlp = d_model * mlp_ratio\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(d_model, d_mlp),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(d_mlp, d_model)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor, cache: Optional[torch.Tensor] = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input of shape (batch, seq_len, d_model)\n",
    "            cache: Optional cached L_KV\n",
    "        Returns:\n",
    "            output: (batch, seq_len, d_model)\n",
    "            L_KV: Updated cache\n",
    "        \"\"\"\n",
    "        # TODO: Implement Pre-LN attention block\n",
    "        # Hint: attn_out, L_KV = self.attn(self.norm1(x), cache)\n",
    "        # Hint: x = x + attn_out\n",
    "\n",
    "        # TODO: Implement Pre-LN MLP block\n",
    "        # Hint: mlp_out = self.mlp(self.norm2(x))\n",
    "        # Hint: x = x + mlp_out\n",
    "\n",
    "        pass  # REPLACE WITH YOUR IMPLEMENTATION\n",
    "\n",
    "# Test the complete block\n",
    "def test_transformer_block():\n",
    "    \"\"\"Test the complete modern transformer block\"\"\"\n",
    "    print(\"Testing Modern Transformer Block...\")\n",
    "\n",
    "    block = ModernTransformerBlock(d_model=256, d_latent=64)\n",
    "\n",
    "    # Forward pass\n",
    "    x = torch.randn(2, 10, 256)\n",
    "    output, cache = block(x)\n",
    "\n",
    "    assert output.shape == x.shape, \"Output shape mismatch\"\n",
    "    assert cache.shape == (2, 10, 64), \"Cache shape mismatch\"\n",
    "    print(f\"  âœ“ Forward pass: {x.shape} -> {output.shape}\")\n",
    "\n",
    "    # Test with cache (autoregressive)\n",
    "    x_next = torch.randn(2, 1, 256)\n",
    "    output_next, cache_next = block(x_next, cache=cache)\n",
    "\n",
    "    assert output_next.shape == (2, 1, 256), \"Cached output shape wrong\"\n",
    "    assert cache_next.shape == (2, 11, 64), \"Updated cache shape wrong\"\n",
    "    print(f\"  âœ“ With cache: {x_next.shape} -> cache {cache_next.shape}\")\n",
    "\n",
    "    print(\"âœ“ Transformer block test passed!\")\n",
    "    print(f\"\\nCache compression: Standard would cache {10 * 256 * 2} values,\")\n",
    "    print(f\"MHLA only caches {10 * 64} values = {(10*256*2)/(10*64):.1f}x smaller!\")\n",
    "\n",
    "# Uncomment to test after implementing all components\n",
    "# test_transformer_block()\n",
    "\n",
    "\"\"\"\n",
    "### Simple Next-Token Prediction Task\n",
    "\n",
    "Let's test our modern transformer on a simple task.\n",
    "\"\"\"\n",
    "\n",
    "def create_toy_dataset(vocab_size: int = 100, seq_len: int = 32, n_samples: int = 1000):\n",
    "    \"\"\"Create a simple synthetic dataset for next-token prediction\"\"\"\n",
    "    # Simple pattern: next token = (current token + 1) mod vocab_size\n",
    "    data = torch.randint(0, vocab_size, (n_samples, seq_len))\n",
    "    targets = (data + 1) % vocab_size\n",
    "    return data, targets\n",
    "\n",
    "def train_model(model, n_epochs: int = 100, vocab_size: int = 100):\n",
    "    \"\"\"Simple training loop\"\"\"\n",
    "    d_model = 256\n",
    "\n",
    "    # Dataset\n",
    "    train_data, train_targets = create_toy_dataset(vocab_size=vocab_size, n_samples=800, seq_len=32)\n",
    "    val_data, val_targets = create_toy_dataset(vocab_size=vocab_size, n_samples=200, seq_len=32)\n",
    "\n",
    "    # Move to device\n",
    "    train_data = train_data.to(device)\n",
    "    train_targets = train_targets.to(device)\n",
    "    val_data = val_data.to(device)\n",
    "    val_targets = val_targets.to(device)\n",
    "\n",
    "    # Embedding and output layers\n",
    "    embedding = nn.Embedding(vocab_size, d_model).to(device)\n",
    "    output_proj = nn.Linear(d_model, vocab_size).to(device)\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Combine into simple model\n",
    "    params = list(model.parameters()) + list(embedding.parameters()) + list(output_proj.parameters())\n",
    "    optimizer = torch.optim.Adam(params, lr=1e-3)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    print(\"Training model...\")\n",
    "    for epoch in range(n_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        x_embed = embedding(train_data)  # (batch, seq, d_model)\n",
    "        output, _ = model(x_embed)\n",
    "        logits = output_proj(output)  # (batch, seq, vocab)\n",
    "\n",
    "        # Loss\n",
    "        loss = F.cross_entropy(\n",
    "            logits.reshape(-1, vocab_size),\n",
    "            train_targets.reshape(-1)\n",
    "        )\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "        # Validation\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                x_embed_val = embedding(val_data)\n",
    "                output_val, _ = model(x_embed_val)\n",
    "                logits_val = output_proj(output_val)\n",
    "                val_loss = F.cross_entropy(\n",
    "                    logits_val.reshape(-1, vocab_size),\n",
    "                    val_targets.reshape(-1)\n",
    "                )\n",
    "                val_losses.append(val_loss.item())\n",
    "\n",
    "                print(f\"Epoch {epoch+1}/{n_epochs} - Train Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}\")\n",
    "\n",
    "    return train_losses, val_losses\n",
    "\n",
    "# Uncomment to train after implementing all components\n",
    "\"\"\"\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training modern transformer on toy task...\")\n",
    "print(\"=\"*60)\n",
    "modern_model = ModernTransformerBlock(d_model=256, d_latent=64)\n",
    "train_losses, val_losses = train_model(modern_model, n_epochs=100)\n",
    "\n",
    "# Plot training curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Train Loss', alpha=0.7, linewidth=1)\n",
    "plt.plot([i*10-1 for i in range(1, len(val_losses)+1)], val_losses, 'o-', label='Val Loss', markersize=6, linewidth=2)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.title('Training Progress: Next-Token Prediction', fontsize=14)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nFinal training loss: {train_losses[-1]:.4f}\")\n",
    "print(f\"Final validation loss: {val_losses[-1]:.4f}\")\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "# Final Questions\n",
    "# ============================================================================\n",
    "\n",
    "\"\"\"\n",
    "## Final Questions\n",
    "\n",
    "**Question 4.1 (3 points - Written):** Imagine you're deploying a chatbot that needs to handle\n",
    "conversations of 50,000 tokens. Would you use standard attention or MHLA?\n",
    "Why? What would be the memory savings?\n",
    "\n",
    "**Your answer here:**\n",
    "\n",
    "\n",
    "**Question 4.2 (3 points - Written):** What's the main trade-off when using a smaller latent dimension\n",
    "$d_{\\text{latent}}$ in MHLA? How would you choose this hyperparameter?\n",
    "\n",
    "**Your answer here:**\n",
    "\n",
    "\n",
    "**Question 4.3 (4 points - Written):** We used Pre-LN (normalize before the block) instead of Post-LN\n",
    "(normalize after the residual). Why is Pre-LN better for deep networks? Hint:\n",
    "think about gradient flow.\n",
    "\n",
    "**Your answer here:**\n",
    "\n",
    "\n",
    "## Submission Checklist\n",
    "\n",
    "Before submitting, make sure you have:\n",
    "- [ ] Implemented RMSNorm correctly (test passes)\n",
    "- [ ] Implemented RoPE correctly (test passes)\n",
    "- [ ] Implemented SimplifiedLatentAttention correctly (test passes)\n",
    "- [ ] Implemented ModernTransformerBlock (test passes)\n",
    "- [ ] Run all comparison visualizations\n",
    "- [ ] Answered all written questions\n",
    "\n",
    "Good luck! ðŸš€\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSNorm output - Mean: -0.0002, Std: 1.0000\n",
      "LayerNorm output - Mean: -0.0000, Std: 1.0000\n",
      "\n",
      "Speed comparison (1000 iterations):\n",
      "RMSNorm: 0.0741s\n",
      "LayerNorm: 0.0203s\n",
      "Note: On CPU, PyTorch's optimized LayerNorm may be faster.\n",
      "      RMSNorm shows speedups on GPU or with optimized kernels.\n",
      "\n",
      "Parameter count:\n",
      "RMSNorm: 512 (only gamma)\n",
      "LayerNorm: 1024 (gamma + beta)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n**Question 1.1 (5 points - Written):** Why doesn\\'t RMSNorm need to compute the mean?\\nIn what way is \"controlling scale\" sufficient for gradient stability?\\n\\n**Your answer here:**\\n\\nRMSNorm is only scaling, it is not centering the mean around zero so there is no need to compute the mean. We are providing a consistent scale across batches and sequences with RMSNorm rather than LayerNorm which does this but while also centering the mean around zero.\\nControlling scale supports gradient stability as the variance is normalized via root-mean-square for activations, this ensures some stability during backpropagation without needing to center the mean around zero since we are pre-layer-normalization.\\n\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Part 1: RMSNorm (20 points)\n",
    "# ============================================================================\n",
    "\n",
    "\"\"\"\n",
    "## Part 1: RMSNorm - Root Mean Square Normalization\n",
    "\n",
    "**Background:** LayerNorm centers (zero mean) and scales (unit variance).\n",
    "RMSNorm only scales, which is simpler and faster while being equally effective in Pre-LN architectures.\n",
    "**Your task:** Complete the RMSNorm implementation below.\n",
    "\"\"\"\n",
    "\n",
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, dim: int, eps: float = 1e-6):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dim: Feature dimension\n",
    "            eps: Small constant for numerical stability\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "        # TODO: Initialize learnable scale parameter (gamma)\n",
    "        # Hint: Use nn.Parameter(torch.ones(dim))\n",
    "        self.gamma = nn.Parameter(torch.ones(dim))\n",
    "        \n",
    "        #self.gamma = None  # REPLACE THIS LINE\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input tensor of shape (batch, seq_len, dim)\n",
    "        Returns:\n",
    "            Normalized tensor of same shape\n",
    "        \"\"\"\n",
    "        # TODO: Implement RMSNorm\n",
    "        # Step 1: Compute mean of squares along last dimension\n",
    "        # Hint: mean_sq = (x ** 2).mean(dim=-1, keepdim=True)\n",
    "        mean_sq = (x ** 2).mean(dim=-1, keepdim=True)\n",
    "\n",
    "        # Step 2: Compute RMS (root mean square)\n",
    "        # Hint: rms = torch.sqrt(mean_sq + self.eps)\n",
    "        rms = torch.sqrt(mean_sq + self.eps)\n",
    "        \n",
    "        # Step 3: Normalize by dividing by RMS\n",
    "        # Hint: x_normalized = x / rms\n",
    "        x_normalized = x / rms\n",
    "\n",
    "        # Step 4: Apply learnable scale\n",
    "        # Hint: return self.gamma * x_normalized\n",
    "        return self.gamma * x_normalized\n",
    "\n",
    "        #pass  # REPLACE WITH YOUR IMPLEMENTATION\n",
    "\n",
    "# Test your implementation\n",
    "def test_rmsnorm():\n",
    "    \"\"\"Test that RMSNorm produces correct scale\"\"\"\n",
    "    print(\"Testing RMSNorm...\")\n",
    "    norm = RMSNorm(dim=64)\n",
    "    x = torch.randn(2, 10, 64)\n",
    "    out = norm(x)\n",
    "\n",
    "    # Check 1: Output should have RMS â‰ˆ 1\n",
    "    rms = torch.sqrt((out ** 2).mean(dim=-1))\n",
    "    assert torch.allclose(rms, torch.ones_like(rms), atol=1e-5), \"RMS should be ~1\"\n",
    "    print(f\"  âœ“ Output RMS: {rms.mean().item():.6f} (should be ~1.0)\")\n",
    "\n",
    "    # Check 2: Compare with LayerNorm - RMSNorm mean is NOT forced to zero\n",
    "    layer_norm = nn.LayerNorm(64)\n",
    "    out_ln = layer_norm(x)\n",
    "\n",
    "    mean_rms = out.mean(dim=-1).abs().mean()\n",
    "    mean_ln = out_ln.mean(dim=-1).abs().mean()\n",
    "\n",
    "    print(f\"  âœ“ RMSNorm output mean: {mean_rms.item():.4f}\")\n",
    "    print(f\"  âœ“ LayerNorm output mean: {mean_ln.item():.6f} (near zero)\")\n",
    "    print(f\"  âœ“ RMSNorm does NOT center data (unlike LayerNorm)\")\n",
    "\n",
    "    print(\"âœ“ RMSNorm test passed!\")\n",
    "    return out\n",
    "\n",
    "# Uncomment to test after implementing\n",
    "# test_rmsnorm()\n",
    "\n",
    "\"\"\"\n",
    "### Comparison: RMSNorm vs LayerNorm\n",
    "\n",
    "Let's compare the two normalization methods.\n",
    "\"\"\"\n",
    "\n",
    "def compare_normalizations():\n",
    "    \"\"\"Compare RMSNorm and LayerNorm\"\"\"\n",
    "    dim = 512\n",
    "    batch, seq_len = 4, 128\n",
    "\n",
    "    # Create input\n",
    "    x = torch.randn(batch, seq_len, dim).to(device)\n",
    "\n",
    "    # Initialize both norms\n",
    "    rms_norm = RMSNorm(dim).to(device)\n",
    "    layer_norm = nn.LayerNorm(dim).to(device)\n",
    "\n",
    "    # Apply both\n",
    "    out_rms = rms_norm(x)\n",
    "    out_ln = layer_norm(x)\n",
    "\n",
    "    # Compare statistics\n",
    "    print(\"RMSNorm output - Mean: {:.4f}, Std: {:.4f}\".format(\n",
    "        out_rms.mean().item(), out_rms.std().item()))\n",
    "    print(\"LayerNorm output - Mean: {:.4f}, Std: {:.4f}\".format(\n",
    "        out_ln.mean().item(), out_ln.std().item()))\n",
    "\n",
    "    # Speed comparison\n",
    "    n_iters = 1000\n",
    "\n",
    "    # Warmup\n",
    "    for _ in range(10):\n",
    "        _ = rms_norm(x)\n",
    "        _ = layer_norm(x)\n",
    "\n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "    # RMSNorm timing\n",
    "    start = time.time()\n",
    "    for _ in range(n_iters):\n",
    "        _ = rms_norm(x)\n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.synchronize()\n",
    "    rms_time = time.time() - start\n",
    "\n",
    "    # LayerNorm timing\n",
    "    start = time.time()\n",
    "    for _ in range(n_iters):\n",
    "        _ = layer_norm(x)\n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.synchronize()\n",
    "    ln_time = time.time() - start\n",
    "\n",
    "    print(f\"\\nSpeed comparison ({n_iters} iterations):\")\n",
    "    print(f\"RMSNorm: {rms_time:.4f}s\")\n",
    "    print(f\"LayerNorm: {ln_time:.4f}s\")\n",
    "    if ln_time > rms_time:\n",
    "        print(f\"Speedup: {ln_time/rms_time:.2f}x\")\n",
    "    else:\n",
    "        print(f\"Note: On CPU, PyTorch's optimized LayerNorm may be faster.\")\n",
    "        print(f\"      RMSNorm shows speedups on GPU or with optimized kernels.\")\n",
    "\n",
    "    # Memory comparison\n",
    "    print(f\"\\nParameter count:\")\n",
    "    print(f\"RMSNorm: {sum(p.numel() for p in rms_norm.parameters())} (only gamma)\")\n",
    "    print(f\"LayerNorm: {sum(p.numel() for p in layer_norm.parameters())} (gamma + beta)\")\n",
    "\n",
    "# Uncomment to run comparison after implementing RMSNorm\n",
    "compare_normalizations()\n",
    "\n",
    "\"\"\"\n",
    "**Question 1.1 (5 points - Written):** Why doesn't RMSNorm need to compute the mean?\n",
    "In what way is \"controlling scale\" sufficient for gradient stability?\n",
    "\n",
    "**Your answer here:**\n",
    "\n",
    "RMSNorm is only scaling, it is not centering the mean around zero so there is no need to compute the mean. We are providing a consistent scale across batches and sequences with RMSNorm rather than LayerNorm which does this but while also centering the mean around zero.\n",
    "Controlling scale supports gradient stability as the variance is normalized via root-mean-square for activations, this ensures some stability during backpropagation without needing to center the mean around zero since we are pre-layer-normalization.\n",
    "\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ljtHbb8POYQz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing RoPE...\n",
      "  Dot product at distance 5 (positions 0â†’5): 57.3730\n",
      "  Dot product at distance 5 (positions 10â†’15): 57.3731\n",
      "  Difference: 0.000008\n",
      "âœ“ RoPE relative position test passed!\n",
      "\n",
      "Testing length extrapolation...\n",
      "  âœ“ Can process sequences longer than some typical lengths (100 tokens)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n**Question 2.1 (5 points - Written):** Why does RoPE generalize better to longer sequences\\nthan learned absolute positional embeddings?\\n\\n**Your answer here:**\\n\\nLearned absolute positional embeddings set a fixed positional embeddings globally, so a position specific vector is added to each tokens embedding. This limits the dimensionality to be the same as the tokens embeddings. Relative position embeddings like RoPE\\nhandle longer sequences better as each tokens embedding has a relative direction to the other embeddings of different tokens, such that each word is looking at other words and how far apart they are. Longer sequences require changing positional encodings as each \\nnew token is searched you need that token positional information but also its relative distance to the other tokens.\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Part 2: Rotary Positional Embeddings (30 points)\n",
    "# ============================================================================\n",
    "\n",
    "\"\"\"\n",
    "## Part 2: RoPE - Rotary Positional Embeddings\n",
    "\n",
    "**Background:** Instead of adding position information to embeddings, RoPE rotates\n",
    "the query and key vectors based on their position. This encodes *relative* position\n",
    "in the attention scores.\n",
    "\n",
    "**Key insight:** After rotation, the dot product between $q_m$ and $k_n$ depends\n",
    "only on the distance $(m-n)$, not absolute positions.\n",
    "\n",
    "**Your task:** Implement RoPE following the steps below.\n",
    "\"\"\"\n",
    "\n",
    "class RotaryEmbedding(nn.Module):\n",
    "    def __init__(self, dim: int, max_seq_len: int = 2048, base: float = 10000.0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dim: Embedding dimension (must be even)\n",
    "            max_seq_len: Maximum sequence length\n",
    "            base: Base for frequency computation\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        assert dim % 2 == 0, \"Dimension must be even\"\n",
    "\n",
    "        # TODO: Compute frequencies: theta_i = base^(-2i/dim) for i in [0, dim/2)\n",
    "        # Hint: inv_freq = 1.0 / (base ** (torch.arange(0, dim, 2).float() / dim))\n",
    "        inv_freq = 1.0 / (base ** (torch.arange(0, dim, 2).float() / dim))\n",
    "        #inv_freq = None  # REPLACE THIS LINE\n",
    "\n",
    "        # TODO: Precompute position indices [0, 1, 2, ..., max_seq_len-1]\n",
    "        # Hint: position = torch.arange(max_seq_len).float()\n",
    "        position = torch.arange(max_seq_len).float()\n",
    "        #position = None  # REPLACE THIS LINE\n",
    "\n",
    "        # TODO: Compute all rotation angles (outer product)\n",
    "        # Hint: freqs = torch.outer(position, inv_freq)\n",
    "        # Shape should be (max_seq_len, dim/2)\n",
    "        freqs = torch.outer(position, inv_freq)\n",
    "        assert freqs.shape == (max_seq_len, dim // 2), f\"Expected shape (max_seq_len, {dim // 2}), but got {freqs.shape}\"\n",
    "        #freqs = None  # REPLACE THIS LINE\n",
    "\n",
    "        # Store as buffer (not a parameter, but part of state)\n",
    "        self.register_buffer('freqs', freqs)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Apply rotary embeddings to input.\n",
    "\n",
    "        Args:\n",
    "            x: Input of shape (batch, seq_len, dim)\n",
    "        Returns:\n",
    "            Rotated input of same shape\n",
    "        \"\"\"\n",
    "        batch, seq_len, dim = x.shape\n",
    "\n",
    "        # Get frequencies for this sequence length\n",
    "        freqs = self.freqs[:seq_len]  # (seq_len, dim/2)\n",
    "\n",
    "        # TODO: Compute cos and sin of frequencies\n",
    "        # Hint: cos_freqs = torch.cos(freqs), sin_freqs = torch.sin(freqs)\n",
    "        cos_freqs = torch.cos(freqs)\n",
    "        sin_freqs = torch.sin(freqs)\n",
    "        #cos_freqs = None  # REPLACE THIS LINE\n",
    "        #sin_freqs = None  # REPLACE THIS LINE\n",
    "\n",
    "        # Reshape x into pairs: (batch, seq_len, dim/2, 2)\n",
    "        x_reshaped = x.reshape(batch, seq_len, -1, 2)\n",
    "\n",
    "        # Split into even and odd indices\n",
    "        x_even = x_reshaped[..., 0]  # (batch, seq_len, dim/2)\n",
    "        x_odd = x_reshaped[..., 1]   # (batch, seq_len, dim/2)\n",
    "\n",
    "        # TODO: Apply rotation using rotation matrix:\n",
    "        # [cos, -sin]\n",
    "        # [sin,  cos]\n",
    "        # Hint: x_even_rot = x_even * cos_freqs - x_odd * sin_freqs\n",
    "        # Hint: x_odd_rot = x_even * sin_freqs + x_odd * cos_freqs\n",
    "        x_even_rot = x_even * cos_freqs - x_odd * sin_freqs\n",
    "        x_odd_rot = x_even * sin_freqs + x_odd * cos_freqs\n",
    "        #x_even_rot = None  # REPLACE THIS LINE\n",
    "        #x_odd_rot = None   # REPLACE THIS LINE\n",
    "\n",
    "        # Stack back together\n",
    "        x_rotated = torch.stack([x_even_rot, x_odd_rot], dim=-1)\n",
    "\n",
    "        # Reshape back to original shape\n",
    "        return x_rotated.reshape(batch, seq_len, dim)\n",
    "\n",
    "# Test RoPE\n",
    "def test_rope():\n",
    "    \"\"\"Test that RoPE encodes relative positions\"\"\"\n",
    "    print(\"Testing RoPE...\")\n",
    "    rope = RotaryEmbedding(dim=64)\n",
    "\n",
    "    # Create separate Q and K vectors (same content, will be rotated differently)\n",
    "    torch.manual_seed(123)  # For reproducibility\n",
    "    base_vec = torch.randn(1, 1, 64)  # Single base vector\n",
    "\n",
    "    # Create Q and K at different positions by repeating the base vector\n",
    "    q_positions = torch.tensor([0, 10])  # Query at positions 0 and 10\n",
    "    k_positions = torch.tensor([5, 15])  # Key at positions 5 and 15\n",
    "\n",
    "    # Create sequences where we place our base vector at specific positions\n",
    "    seq_len = 20\n",
    "    Q = torch.zeros(1, seq_len, 64)\n",
    "    K = torch.zeros(1, seq_len, 64)\n",
    "\n",
    "    # Place the same base vector at different positions\n",
    "    Q[0, q_positions[0]] = base_vec[0, 0]\n",
    "    Q[0, q_positions[1]] = base_vec[0, 0]\n",
    "    K[0, k_positions[0]] = base_vec[0, 0]\n",
    "    K[0, k_positions[1]] = base_vec[0, 0]\n",
    "\n",
    "    # Apply RoPE\n",
    "    Q_rot = rope(Q)\n",
    "    K_rot = rope(K)\n",
    "\n",
    "    # Test relative position property\n",
    "    # dot(q@pos0, k@pos5) should equal dot(q@pos10, k@pos15) (both have distance 5)\n",
    "    dot1 = (Q_rot[0, q_positions[0]] * K_rot[0, k_positions[0]]).sum()\n",
    "    dot2 = (Q_rot[0, q_positions[1]] * K_rot[0, k_positions[1]]).sum()\n",
    "\n",
    "    print(f\"  Dot product at distance 5 (positions 0â†’5): {dot1:.4f}\")\n",
    "    print(f\"  Dot product at distance 5 (positions 10â†’15): {dot2:.4f}\")\n",
    "    print(f\"  Difference: {(dot1 - dot2).abs():.6f}\")\n",
    "\n",
    "    assert torch.allclose(dot1, dot2, atol=1e-3), \"Should encode relative position!\"\n",
    "    print(\"âœ“ RoPE relative position test passed!\")\n",
    "\n",
    "    # Test length extrapolation\n",
    "    print(\"\\nTesting length extrapolation...\")\n",
    "    x_long = torch.randn(1, 100, 64)\n",
    "    x_long_rotated = rope(x_long)\n",
    "    print(f\"  âœ“ Can process sequences longer than some typical lengths ({x_long.shape[1]} tokens)\")\n",
    "\n",
    "# Uncomment to test after implementing\n",
    "test_rope()\n",
    "\n",
    "\"\"\"\n",
    "### Visualize RoPE\n",
    "\n",
    "Let's visualize how RoPE encodes positions.\n",
    "\"\"\"\n",
    "\n",
    "def visualize_rope():\n",
    "    \"\"\"Visualize RoPE attention patterns\"\"\"\n",
    "    rope = RotaryEmbedding(dim=64)\n",
    "\n",
    "    # Create queries and keys at different positions\n",
    "    seq_len = 50\n",
    "    x = torch.randn(1, seq_len, 64)\n",
    "    x_rotated = rope(x)\n",
    "\n",
    "    # Compute attention scores (without softmax)\n",
    "    scores = torch.matmul(x_rotated, x_rotated.transpose(-2, -1))\n",
    "    scores = scores[0].detach().numpy()  # (seq_len, seq_len)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Full attention matrix\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(scores, cmap='viridis', aspect='auto')\n",
    "    plt.colorbar(label='Attention Score')\n",
    "    plt.xlabel('Key Position')\n",
    "    plt.ylabel('Query Position')\n",
    "    plt.title('Attention Scores with RoPE')\n",
    "\n",
    "    # Attention as function of relative distance\n",
    "    plt.subplot(1, 3, 2)\n",
    "    distances = []\n",
    "    avg_scores = []\n",
    "    for d in range(25):\n",
    "        # Get all pairs with distance d\n",
    "        mask = torch.zeros(seq_len, seq_len)\n",
    "        for i in range(seq_len - d):\n",
    "            mask[i, i + d] = 1\n",
    "\n",
    "        if mask.sum() > 0:\n",
    "            avg_score = (torch.tensor(scores) * mask).sum() / mask.sum()\n",
    "            distances.append(d)\n",
    "            avg_scores.append(avg_score.item())\n",
    "\n",
    "    plt.plot(distances, avg_scores, marker='o', linewidth=2)\n",
    "    plt.xlabel('Relative Distance')\n",
    "    plt.ylabel('Average Attention Score')\n",
    "    plt.title('Attention vs Relative Position')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    # Show that position 0 has same pattern as position 20\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(scores[0, :], label='Query at position 0', linewidth=2)\n",
    "    plt.plot(scores[20, :], label='Query at position 20', linewidth=2, linestyle='--')\n",
    "    plt.xlabel('Key Position')\n",
    "    plt.ylabel('Attention Score')\n",
    "    plt.title('RoPE Relative Position Property')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Notice: The patterns are shifted but have the same shape!\")\n",
    "    print(\"This shows that RoPE encodes relative position, not absolute position.\")\n",
    "\n",
    "# Uncomment to visualize after implementing\n",
    "# visualize_rope()\n",
    "\n",
    "\"\"\"\n",
    "**Question 2.1 (5 points - Written):** Why does RoPE generalize better to longer sequences\n",
    "than learned absolute positional embeddings?\n",
    "\n",
    "**Your answer here:**\n",
    "\n",
    "Learned absolute positional embeddings set a fixed positional embeddings globally, so a position specific vector is added to each tokens embedding. This limits the dimensionality to be the same as the tokens embeddings. Relative position embeddings like RoPE\n",
    "handle longer sequences better as each tokens embedding has a relative direction to the other embeddings of different tokens, such that each word is looking at other words and how far apart they are. Longer sequences require changing positional encodings as each \n",
    "new token is searched you need that token positional information but also its relative distance to the other tokens.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing MHLA...\n",
      "  âœ“ Forward pass: input torch.Size([2, 10, 256]) -> output torch.Size([2, 10, 256])\n",
      "  âœ“ Cache shape: torch.Size([2, 10, 64])\n",
      "  âœ“ With cache: new input torch.Size([2, 1, 256]) -> cache torch.Size([2, 11, 64])\n",
      "âœ“ MHLA test passed!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For d_model=256, d_latent=64:\n",
      "Compression ratio: 8.0x\n",
      "At seq_len=2000: Standard=1,024,000 vs MHLA=128,000\n",
      "Memory savings: 87.5%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n**Question 3.1 (5 points - Written):** The compression ratio is constant regardless of sequence\\nlength. Why? What does this tell you about where the memory savings come from?\\n\\n**Your answer here:**\\n\\nThe compression ratio is constant because it only depends on the dimension space not the sequence length. Our standard attention is caching K and V matrixes but MHLA is compressing these into a single latent vector. For our memroy savings this means it \\ncomes from the latent spaces (of lower dimension).\\n\\n\\n**Question 3.2 (5 points - Written):** MHLA compresses K and V significantly. What information\\nmight be lost? In what scenarios might this hurt model quality?\\n\\n**Your answer here:**\\n\\nInformation about minute detail say token level would be lost and information about patterns across heads which would lead to less complex findings but a quicker more general learning by the model. This would hurt if you are looking for specific outcomes for \\nthe model to focus on like minute details about specific token, embeddings, or positions and if you want a deep learning of complex features (that say individual features span a wide number of tokens but show only minimally in total) then the model would like \\nperform poorly.\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Part 3: Simplified Multi-Head Latent Attention (35 points)\n",
    "# ============================================================================\n",
    "\n",
    "\"\"\"\n",
    "## Part 3: Simplified MHLA\n",
    "\n",
    "**Background:** Standard attention caches both K and V for all heads, which uses\n",
    "a lot of memory. MHLA compresses K and V into a lower-dimensional \"latent\" space.\n",
    "\n",
    "**Standard attention cache per token:** $2 \\times n_{\\text{heads}} \\times d_{\\text{head}}$\n",
    "\n",
    "**MHLA cache per token:** $d_{\\text{latent}}$ (much smaller!)\n",
    "\n",
    "**Your task:** Implement a simplified single-head version of MHLA.\n",
    "\"\"\"\n",
    "\n",
    "class SimplifiedLatentAttention(nn.Module):\n",
    "    def __init__(self, d_model: int = 256, d_latent: int = 64):\n",
    "        \"\"\"\n",
    "        Simplified Multi-Head Latent Attention (single head version)\n",
    "\n",
    "        Args:\n",
    "            d_model: Model dimension\n",
    "            d_latent: Latent dimension (compressed, this is what gets cached)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_latent = d_latent\n",
    "        self.scale = math.sqrt(d_latent)\n",
    "\n",
    "        # TODO: Initialize projection matrices (all with bias=False)\n",
    "        # W_DKV: projects input to latent KV space (d_model -> d_latent)\n",
    "        # W_Q: projects input to query space (d_model -> d_model)\n",
    "        # W_UK: projects queries to latent space (d_model -> d_latent)\n",
    "        # W_O: projects latent output back to model space (d_latent -> d_model)\n",
    "        # Hint: Use nn.Linear(in_features, out_features, bias=False)\n",
    "        self.W_DKV = nn.Linear(d_model, d_latent, bias=False)\n",
    "        self.W_Q = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.W_UK = nn.Linear(d_model, d_latent, bias=False)\n",
    "        self.W_O = nn.Linear(d_latent, d_model, bias=False)\n",
    "        \n",
    "        #self.W_DKV = None   # REPLACE THIS LINE\n",
    "        #self.W_Q = None     # REPLACE THIS LINE\n",
    "        #self.W_UK = None    # REPLACE THIS LINE\n",
    "        #self.W_O = None     # REPLACE THIS LINE\n",
    "\n",
    "    def forward(self, x: torch.Tensor, cache: Optional[torch.Tensor] = None) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input of shape (batch, seq_len, d_model)\n",
    "            cache: Optional cached L_KV from previous steps\n",
    "        Returns:\n",
    "            output: (batch, seq_len, d_model)\n",
    "            L_KV: (batch, total_seq_len, d_latent) for caching\n",
    "        \"\"\"\n",
    "        batch, seq_len, _ = x.shape\n",
    "\n",
    "        # TODO: Step 1 - Create KV latent (THIS is what gets cached!)\n",
    "        # Hint: L_KV_new = self.W_DKV(x)\n",
    "        # Shape: (batch, seq_len, d_latent)\n",
    "        L_KV_new = self.W_DKV(x)\n",
    "\n",
    "        #L_KV_new = None  # REPLACE THIS LINE\n",
    "\n",
    "        # TODO: Step 2 - Create queries and project to latent space\n",
    "        # Hint: Q = self.W_Q(x), then QK_T = self.W_UK(Q)\n",
    "        # QK_T shape: (batch, seq_len, d_latent)\n",
    "        Q = self.W_Q(x)\n",
    "        QK_T = self.W_UK(Q)\n",
    "        #Q = None       # REPLACE THIS LINE\n",
    "        #QK_T = None    # REPLACE THIS LINE\n",
    "\n",
    "        # Step 3: Handle cache (for autoregressive generation)\n",
    "        if cache is not None:\n",
    "            # Concatenate with previous L_KV\n",
    "            L_KV = torch.cat([cache, L_KV_new], dim=1)\n",
    "        else:\n",
    "            L_KV = L_KV_new\n",
    "\n",
    "        # TODO: Step 4 - Compute attention scores in latent space\n",
    "        # Hint: scores = (QK_T @ L_KV.transpose(-2, -1)) / self.scale\n",
    "        # Shape: (batch, seq_len, total_seq_len)\n",
    "        scores = (QK_T @ L_KV.transpose(-2, -1)) / self.scale\n",
    "        #scores = None  # REPLACE THIS LINE\n",
    "\n",
    "        # TODO: Step 5 - Apply softmax\n",
    "        # Hint: attn_weights = F.softmax(scores, dim=-1)\n",
    "        attn_weights = F.softmax(scores, dim=-1)\n",
    "        #attn_weights = None  # REPLACE THIS LINE\n",
    "\n",
    "        # TODO: Step 6 - Weighted sum of latent values\n",
    "        # Hint: weighted_latents = attn_weights @ L_KV\n",
    "        # Shape: (batch, seq_len, d_latent)\n",
    "        weighted_latents = attn_weights @ L_KV\n",
    "        #weighted_latents = None  # REPLACE THIS LINE\\\n",
    "        \n",
    "        # TODO: Step 7 - Project back to model dimension\n",
    "        # Hint: output = self.W_O(weighted_latents)\n",
    "        # Shape: (batch, seq_len, d_model)\n",
    "        output = self.W_O(weighted_latents)\n",
    "        #output = None  # REPLACE THIS LINE\n",
    "\n",
    "        return output, L_KV\n",
    "\n",
    "# Test MHLA\n",
    "def test_mhla():\n",
    "    \"\"\"Test SimplifiedLatentAttention\"\"\"\n",
    "    print(\"Testing MHLA...\")\n",
    "\n",
    "    d_model, d_latent = 256, 64\n",
    "    mhla = SimplifiedLatentAttention(d_model, d_latent)\n",
    "\n",
    "    # Test forward pass\n",
    "    x = torch.randn(2, 10, d_model)\n",
    "    output, L_KV = mhla(x)\n",
    "\n",
    "    # Check shapes\n",
    "    assert output.shape == x.shape, f\"Output shape mismatch: {output.shape} vs {x.shape}\"\n",
    "    assert L_KV.shape == (2, 10, d_latent), f\"L_KV shape mismatch: {L_KV.shape}\"\n",
    "    print(f\"  âœ“ Forward pass: input {x.shape} -> output {output.shape}\")\n",
    "    print(f\"  âœ“ Cache shape: {L_KV.shape}\")\n",
    "\n",
    "    # Test with cache\n",
    "    x_next = torch.randn(2, 1, d_model)\n",
    "    output_next, L_KV_next = mhla(x_next, cache=L_KV)\n",
    "\n",
    "    assert output_next.shape == (2, 1, d_model), \"Cached output shape wrong\"\n",
    "    assert L_KV_next.shape == (2, 11, d_latent), \"Cached L_KV shape wrong\"\n",
    "    print(f\"  âœ“ With cache: new input {x_next.shape} -> cache {L_KV_next.shape}\")\n",
    "\n",
    "    print(\"âœ“ MHLA test passed!\")\n",
    "\n",
    "# Uncomment to test after implementing\n",
    "test_mhla()\n",
    "\n",
    "\"\"\"\n",
    "### Standard Attention for Comparison\n",
    "\n",
    "Here's standard attention implemented for comparison (already complete).\n",
    "\"\"\"\n",
    "\n",
    "class StandardAttention(nn.Module):\n",
    "    def __init__(self, d_model: int = 256):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.scale = math.sqrt(d_model)\n",
    "\n",
    "        self.W_Q = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.W_K = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.W_V = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.W_O = nn.Linear(d_model, d_model, bias=False)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, cache: Optional[Tuple[torch.Tensor, torch.Tensor]] = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input of shape (batch, seq_len, d_model)\n",
    "            cache: Optional tuple of (cached_K, cached_V)\n",
    "        Returns:\n",
    "            output: (batch, seq_len, d_model)\n",
    "            (K, V): Tuple for caching\n",
    "        \"\"\"\n",
    "        Q = self.W_Q(x)\n",
    "        K_new = self.W_K(x)\n",
    "        V_new = self.W_V(x)\n",
    "\n",
    "        # Handle cache\n",
    "        if cache is not None:\n",
    "            K_cache, V_cache = cache\n",
    "            K = torch.cat([K_cache, K_new], dim=1)\n",
    "            V = torch.cat([V_cache, V_new], dim=1)\n",
    "        else:\n",
    "            K, V = K_new, V_new\n",
    "\n",
    "        # Attention\n",
    "        scores = (Q @ K.transpose(-2, -1)) / self.scale\n",
    "        attn_weights = F.softmax(scores, dim=-1)\n",
    "        output = attn_weights @ V\n",
    "        output = self.W_O(output)\n",
    "\n",
    "        return output, (K, V)\n",
    "\n",
    "\"\"\"\n",
    "### Compare MHLA vs Standard Attention\n",
    "\"\"\"\n",
    "\n",
    "def compare_attention_mechanisms():\n",
    "    \"\"\"Compare cache sizes and efficiency\"\"\"\n",
    "    d_model = 256\n",
    "    d_latent = 64\n",
    "    seq_lengths = [50, 100, 200, 500, 1000, 2000]\n",
    "\n",
    "    mhla = SimplifiedLatentAttention(d_model, d_latent)\n",
    "    std_attn = StandardAttention(d_model)\n",
    "\n",
    "    mhla_cache_sizes = []\n",
    "    std_cache_sizes = []\n",
    "\n",
    "    for seq_len in seq_lengths:\n",
    "        # MHLA cache: only L_KV\n",
    "        mhla_cache = seq_len * d_latent\n",
    "        mhla_cache_sizes.append(mhla_cache)\n",
    "\n",
    "        # Standard attention cache: both K and V\n",
    "        std_cache = seq_len * d_model * 2\n",
    "        std_cache_sizes.append(std_cache)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Cache size comparison\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(seq_lengths, np.array(std_cache_sizes)/1000, 'o-', label='Standard Attention', linewidth=2, markersize=8)\n",
    "    plt.plot(seq_lengths, np.array(mhla_cache_sizes)/1000, 's-', label='MHLA', linewidth=2, markersize=8)\n",
    "    plt.xlabel('Sequence Length', fontsize=12)\n",
    "    plt.ylabel('Cache Size (thousands of values)', fontsize=12)\n",
    "    plt.title('KV Cache Size vs Sequence Length', fontsize=14)\n",
    "    plt.legend(fontsize=11)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    # Compression ratio\n",
    "    plt.subplot(1, 2, 2)\n",
    "    ratios = [std / mhla for std, mhla in zip(std_cache_sizes, mhla_cache_sizes)]\n",
    "    plt.plot(seq_lengths, ratios, 'o-', linewidth=2, markersize=8, color='green')\n",
    "    plt.axhline(y=ratios[0], color='gray', linestyle='--', alpha=0.5, label=f'{ratios[0]:.1f}x (constant)')\n",
    "    plt.xlabel('Sequence Length', fontsize=12)\n",
    "    plt.ylabel('Compression Ratio', fontsize=12)\n",
    "    plt.title('Cache Compression: Standard / MHLA', fontsize=14)\n",
    "    plt.legend(fontsize=11)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"\\nFor d_model={d_model}, d_latent={d_latent}:\")\n",
    "    print(f\"Compression ratio: {ratios[0]:.1f}x\")\n",
    "    print(f\"At seq_len=2000: Standard={std_cache_sizes[-1]:,} vs MHLA={mhla_cache_sizes[-1]:,}\")\n",
    "    print(f\"Memory savings: {(1 - mhla_cache_sizes[-1]/std_cache_sizes[-1])*100:.1f}%\")\n",
    "\n",
    "# Uncomment to run comparison after implementing MHLA\n",
    "compare_attention_mechanisms()\n",
    "\n",
    "\"\"\"\n",
    "**Question 3.1 (5 points - Written):** The compression ratio is constant regardless of sequence\n",
    "length. Why? What does this tell you about where the memory savings come from?\n",
    "\n",
    "**Your answer here:**\n",
    "\n",
    "The compression ratio is constant because it only depends on the dimension space not the sequence length. Our standard attention is caching K and V matrixes but MHLA is compressing these into a single latent vector. For our memroy savings this means it \n",
    "comes from the latent spaces (of lower dimension).\n",
    "\n",
    "\n",
    "**Question 3.2 (5 points - Written):** MHLA compresses K and V significantly. What information\n",
    "might be lost? In what scenarios might this hurt model quality?\n",
    "\n",
    "**Your answer here:**\n",
    "\n",
    "Information about minute detail say token level would be lost and information about patterns across heads which would lead to less complex findings but a quicker more general learning by the model. This would hurt if you are looking for specific outcomes for \n",
    "the model to focus on like minute details about specific token, embeddings, or positions and if you want a deep learning of complex features (that say individual features span a wide number of tokens but show only minimally in total) then the model would like \n",
    "perform poorly.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Modern Transformer Block...\n",
      "  âœ“ Forward pass: torch.Size([2, 10, 256]) -> torch.Size([2, 10, 256])\n",
      "  âœ“ With cache: torch.Size([2, 1, 256]) -> cache torch.Size([2, 11, 64])\n",
      "âœ“ Transformer block test passed!\n",
      "\n",
      "Cache compression: Standard would cache 5120 values,\n",
      "MHLA only caches 640 values = 8.0x smaller!\n",
      "\n",
      "============================================================\n",
      "Training modern transformer on toy task...\n",
      "============================================================\n",
      "Training model...\n",
      "Epoch 10/100 - Train Loss: 0.2848, Val Loss: 0.1502\n",
      "Epoch 20/100 - Train Loss: 0.0011, Val Loss: 0.0008\n",
      "Epoch 30/100 - Train Loss: 0.0001, Val Loss: 0.0001\n",
      "Epoch 40/100 - Train Loss: 0.0001, Val Loss: 0.0000\n",
      "Epoch 50/100 - Train Loss: 0.0000, Val Loss: 0.0000\n",
      "Epoch 60/100 - Train Loss: 0.0000, Val Loss: 0.0000\n",
      "Epoch 70/100 - Train Loss: 0.0000, Val Loss: 0.0000\n",
      "Epoch 80/100 - Train Loss: 0.0000, Val Loss: 0.0000\n",
      "Epoch 90/100 - Train Loss: 0.0000, Val Loss: 0.0000\n",
      "Epoch 100/100 - Train Loss: 0.0000, Val Loss: 0.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final training loss: 0.0000\n",
      "Final validation loss: 0.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n## Final Questions\\n\\n**Question 4.1 (3 points - Written):** Imagine you're deploying a chatbot that needs to handle\\nconversations of 50,000 tokens. Would you use standard attention or MHLA?\\nWhy? What would be the memory savings?\\n\\n**Your answer here:**\\n\\nI would use MHLA to greatly reduce the number of parameters and therefore cache per token. For 50k tokens, the memory savings would be say model dimensions = 256 and latent dimension = 64. The MHLA cache per token would be 64 just like above at a 8x rate so \\nthe memory savings would be 50k x 512 = 25.6M and 50k x 64 = 3.2M so you are left with about 12.5% of memory used from the standard attentino of 25.6M (87.5% reduction).\\n\\n\\n**Question 4.2 (3 points - Written):** What's the main trade-off when using a smaller latent dimension\\n$d_{\\text{latent}}$ in MHLA? How would you choose this hyperparameter?\\n\\n**Your answer here:**\\n\\nYou lose a good deal of information in the compression amd matrix manipulation. You would look at the problem being solved and consider whether you want less compression for greater information retention, more compression so greater memory savings and speed \\nbut losing a greater deal of information or somewhere inbetween. Usually though in our examples and papers online there is some standardization like 64 latents, 128, 256 etc. leaving d_model / 4 = d_latent as a good starting point.\\n\\n\\n**Question 4.3 (4 points - Written):** We used Pre-LN (normalize before the block) instead of Post-LN\\n(normalize after the residual). Why is Pre-LN better for deep networks? Hint:\\nthink about gradient flow.\\n\\n**Your answer here:**\\n\\nPre-LayerNormalization is better for deep network as the backpropagation does not need to span every layer fixing on stabilizing variance and mean but rather just variance. In a deep network each forward could have a very long backpropagation and we reduce \\nthis complexity by foregoing the need to center the mean. The exploding gradient and vanishing gradient problems exist for both Post-LN and Pre-LN however by normalizing the sub-layer inputs in Pre-LNwe get better convergence and greatly reduce the vanishing \\ngradient problem.\\n\\n\\n## Submission Checklist\\n\\nBefore submitting, make sure you have:\\n- [ ] Implemented RMSNorm correctly (test passes)\\n- [ ] Implemented RoPE correctly (test passes)\\n- [ ] Implemented SimplifiedLatentAttention correctly (test passes)\\n- [ ] Implemented ModernTransformerBlock (test passes)\\n- [ ] Run all comparison visualizations\\n- [ ] Answered all written questions\\n\\nGood luck! ðŸš€\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Part 4: Putting It All Together (15 points)\n",
    "# ============================================================================\n",
    "\n",
    "\"\"\"\n",
    "## Part 4: Complete Transformer Block\n",
    "\n",
    "Now let's combine everything into a modern Transformer block.\n",
    "\"\"\"\n",
    "\n",
    "class ModernTransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model: int = 256, d_latent: int = 64, mlp_ratio: int = 4):\n",
    "        \"\"\"\n",
    "        Modern Transformer block with:\n",
    "        - Pre-LN architecture\n",
    "        - RMSNorm\n",
    "        - Simplified MHLA\n",
    "        - Standard MLP\n",
    "\n",
    "        Args:\n",
    "            d_model: Model dimension\n",
    "            d_latent: Latent dimension for MHLA\n",
    "            mlp_ratio: MLP expansion ratio\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Normalization (Pre-LN style)\n",
    "        self.norm1 = RMSNorm(d_model)\n",
    "        self.norm2 = RMSNorm(d_model)\n",
    "\n",
    "        # Attention\n",
    "        self.attn = SimplifiedLatentAttention(d_model, d_latent)\n",
    "\n",
    "        # MLP\n",
    "        d_mlp = d_model * mlp_ratio\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(d_model, d_mlp),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(d_mlp, d_model)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor, cache: Optional[torch.Tensor] = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input of shape (batch, seq_len, d_model)\n",
    "            cache: Optional cached L_KV\n",
    "        Returns:\n",
    "            output: (batch, seq_len, d_model)\n",
    "            L_KV: Updated cache\n",
    "        \"\"\"\n",
    "        # TODO: Implement Pre-LN attention block\n",
    "        # Hint: attn_out, L_KV = self.attn(self.norm1(x), cache)\n",
    "        # Hint: x = x + attn_out\n",
    "        attn_out, L_KV = self.attn(self.norm1(x), cache)\n",
    "        x = x + attn_out\n",
    "        \n",
    "        # TODO: Implement Pre-LN MLP block\n",
    "        # Hint: mlp_out = self.mlp(self.norm2(x))\n",
    "        # Hint: x = x + mlp_out\n",
    "        mlp_out = self.mlp(self.norm2(x))\n",
    "        x = x + mlp_out\n",
    "        \n",
    "        return x, L_KV\n",
    "        #pass  # REPLACE WITH YOUR IMPLEMENTATION\n",
    "        \n",
    "\n",
    "# Test the complete block\n",
    "def test_transformer_block():\n",
    "    \"\"\"Test the complete modern transformer block\"\"\"\n",
    "    print(\"Testing Modern Transformer Block...\")\n",
    "\n",
    "    block = ModernTransformerBlock(d_model=256, d_latent=64)\n",
    "\n",
    "    # Forward pass\n",
    "    x = torch.randn(2, 10, 256)\n",
    "    output, cache = block(x)\n",
    "\n",
    "    assert output.shape == x.shape, \"Output shape mismatch\"\n",
    "    assert cache.shape == (2, 10, 64), \"Cache shape mismatch\"\n",
    "    print(f\"  âœ“ Forward pass: {x.shape} -> {output.shape}\")\n",
    "\n",
    "    # Test with cache (autoregressive)\n",
    "    x_next = torch.randn(2, 1, 256)\n",
    "    output_next, cache_next = block(x_next, cache=cache)\n",
    "\n",
    "    assert output_next.shape == (2, 1, 256), \"Cached output shape wrong\"\n",
    "    assert cache_next.shape == (2, 11, 64), \"Updated cache shape wrong\"\n",
    "    print(f\"  âœ“ With cache: {x_next.shape} -> cache {cache_next.shape}\")\n",
    "\n",
    "    print(\"âœ“ Transformer block test passed!\")\n",
    "    print(f\"\\nCache compression: Standard would cache {10 * 256 * 2} values,\")\n",
    "    print(f\"MHLA only caches {10 * 64} values = {(10*256*2)/(10*64):.1f}x smaller!\")\n",
    "\n",
    "# Uncomment to test after implementing all components\n",
    "test_transformer_block()\n",
    "\n",
    "\"\"\"\n",
    "### Simple Next-Token Prediction Task\n",
    "\n",
    "Let's test our modern transformer on a simple task.\n",
    "\"\"\"\n",
    "\n",
    "def create_toy_dataset(vocab_size: int = 100, seq_len: int = 32, n_samples: int = 1000):\n",
    "    \"\"\"Create a simple synthetic dataset for next-token prediction\"\"\"\n",
    "    # Simple pattern: next token = (current token + 1) mod vocab_size\n",
    "    data = torch.randint(0, vocab_size, (n_samples, seq_len))\n",
    "    targets = (data + 1) % vocab_size\n",
    "    return data, targets\n",
    "\n",
    "def train_model(model, n_epochs: int = 100, vocab_size: int = 100):\n",
    "    \"\"\"Simple training loop\"\"\"\n",
    "    d_model = 256\n",
    "\n",
    "    # Dataset\n",
    "    train_data, train_targets = create_toy_dataset(vocab_size=vocab_size, n_samples=800, seq_len=32)\n",
    "    val_data, val_targets = create_toy_dataset(vocab_size=vocab_size, n_samples=200, seq_len=32)\n",
    "\n",
    "    # Move to device\n",
    "    train_data = train_data.to(device)\n",
    "    train_targets = train_targets.to(device)\n",
    "    val_data = val_data.to(device)\n",
    "    val_targets = val_targets.to(device)\n",
    "\n",
    "    # Embedding and output layers\n",
    "    embedding = nn.Embedding(vocab_size, d_model).to(device)\n",
    "    output_proj = nn.Linear(d_model, vocab_size).to(device)\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Combine into simple model\n",
    "    params = list(model.parameters()) + list(embedding.parameters()) + list(output_proj.parameters())\n",
    "    optimizer = torch.optim.Adam(params, lr=1e-3)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    print(\"Training model...\")\n",
    "    for epoch in range(n_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        x_embed = embedding(train_data)  # (batch, seq, d_model)\n",
    "        output, _ = model(x_embed)\n",
    "        logits = output_proj(output)  # (batch, seq, vocab)\n",
    "\n",
    "        # Loss\n",
    "        loss = F.cross_entropy(\n",
    "            logits.reshape(-1, vocab_size),\n",
    "            train_targets.reshape(-1)\n",
    "        )\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "        # Validation\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                x_embed_val = embedding(val_data)\n",
    "                output_val, _ = model(x_embed_val)\n",
    "                logits_val = output_proj(output_val)\n",
    "                val_loss = F.cross_entropy(\n",
    "                    logits_val.reshape(-1, vocab_size),\n",
    "                    val_targets.reshape(-1)\n",
    "                )\n",
    "                val_losses.append(val_loss.item())\n",
    "\n",
    "                print(f\"Epoch {epoch+1}/{n_epochs} - Train Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}\")\n",
    "\n",
    "    return train_losses, val_losses\n",
    "\n",
    "# Uncomment to train after implementing all components\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training modern transformer on toy task...\")\n",
    "print(\"=\"*60)\n",
    "modern_model = ModernTransformerBlock(d_model=256, d_latent=64)\n",
    "train_losses, val_losses = train_model(modern_model, n_epochs=100)\n",
    "\n",
    "# Plot training curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Train Loss', alpha=0.7, linewidth=1)\n",
    "plt.plot([i*10-1 for i in range(1, len(val_losses)+1)], val_losses, 'o-', label='Val Loss', markersize=6, linewidth=2)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.title('Training Progress: Next-Token Prediction', fontsize=14)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nFinal training loss: {train_losses[-1]:.4f}\")\n",
    "print(f\"Final validation loss: {val_losses[-1]:.4f}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Final Questions\n",
    "# ============================================================================\n",
    "\n",
    "\"\"\"\n",
    "## Final Questions\n",
    "\n",
    "**Question 4.1 (3 points - Written):** Imagine you're deploying a chatbot that needs to handle\n",
    "conversations of 50,000 tokens. Would you use standard attention or MHLA?\n",
    "Why? What would be the memory savings?\n",
    "\n",
    "**Your answer here:**\n",
    "\n",
    "I would use MHLA to greatly reduce the number of parameters and therefore cache per token. For 50k tokens, the memory savings would be say model dimensions = 256 and latent dimension = 64. The MHLA cache per token would be 64 just like above at a 8x rate so \n",
    "the memory savings would be 50k x 512 = 25.6M and 50k x 64 = 3.2M so you are left with about 12.5% of memory used from the standard attentino of 25.6M (87.5% reduction).\n",
    "\n",
    "\n",
    "**Question 4.2 (3 points - Written):** What's the main trade-off when using a smaller latent dimension\n",
    "$d_{\\text{latent}}$ in MHLA? How would you choose this hyperparameter?\n",
    "\n",
    "**Your answer here:**\n",
    "\n",
    "You lose a good deal of information in the compression amd matrix manipulation. You would look at the problem being solved and consider whether you want less compression for greater information retention, more compression so greater memory savings and speed \n",
    "but losing a greater deal of information or somewhere inbetween. Usually though in our examples and papers online there is some standardization like 64 latents, 128, 256 etc. leaving d_model / 4 = d_latent as a good starting point.\n",
    "\n",
    "\n",
    "**Question 4.3 (4 points - Written):** We used Pre-LN (normalize before the block) instead of Post-LN\n",
    "(normalize after the residual). Why is Pre-LN better for deep networks? Hint:\n",
    "think about gradient flow.\n",
    "\n",
    "**Your answer here:**\n",
    "\n",
    "Pre-LayerNormalization is better for deep network as the backpropagation does not need to span every layer fixing on stabilizing variance and mean but rather just variance. In a deep network each forward could have a very long backpropagation and we reduce \n",
    "this complexity by foregoing the need to center the mean. The exploding gradient and vanishing gradient problems exist for both Post-LN and Pre-LN however by normalizing the sub-layer inputs in Pre-LNwe get better convergence and greatly reduce the vanishing \n",
    "gradient problem.\n",
    "\n",
    "\n",
    "## Submission Checklist\n",
    "\n",
    "Before submitting, make sure you have:\n",
    "- [ ] Implemented RMSNorm correctly (test passes)\n",
    "- [ ] Implemented RoPE correctly (test passes)\n",
    "- [ ] Implemented SimplifiedLatentAttention correctly (test passes)\n",
    "- [ ] Implemented ModernTransformerBlock (test passes)\n",
    "- [ ] Run all comparison visualizations\n",
    "- [ ] Answered all written questions\n",
    "\n",
    "Good luck! ðŸš€\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dsvenv",
   "language": "python",
   "name": "dsvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
