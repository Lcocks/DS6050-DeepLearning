{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Lcocks/DS6050-DeepLearning/blob/main/German_credit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vVsCHeU2K9a4"
   },
   "source": [
    "https://colab.research.google.com/drive/1Z4h7a98YGhJ65L3_QsfEe0FOaZh8hTHT?usp=sharing\n",
    "\n",
    "https://archive.ics.uci.edu/dataset/144/statlog+german+credit+data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "H7IpHjI9K4F6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Part 1: Vanilla MLP Baseline for German Credit Risk Prediction\n",
    "Dataset (UCI ML Repository):\n",
    "- Name: Statlog (German Credit Data)\n",
    "- Direct data file used here (space-separated):\n",
    "  https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data\n",
    "- Approx. size: 1,000 rows × 20 features + 1 label (the 21st column named `class`).\n",
    "- Label encoding in the raw file: 1 = Good credit, 2 = Bad credit.\n",
    "  We remap to: 0 = Good, 1 = Bad (binary classification with \"Bad\" as the positive class).\n",
    "\n",
    "Caveats:\n",
    "- This dataset mixes numeric and categorical (string-coded) features such as 'A11'.\n",
    "  In this baseline, we use LabelEncoder per categorical column + StandardScaler on numerics.\n",
    "  A stronger approach might use embeddings or target encoding for high-cardinality variables.\n",
    "\n",
    "What you should expect:\n",
    "- Because \"Bad Credit\" is the minority class (~30% in the full dataset), a vanilla model\n",
    "  with a 0.5 threshold typically has *lower recall* on \"Bad\" (misses risky cases).\n",
    "- Still, the AUC can look decent (e.g., ~0.78–0.80) because the model ranks many\n",
    "  \"Bad\" cases higher than \"Good\" even if we choose a suboptimal decision threshold.\n",
    "\n",
    "  1) Download the dataset if 'german.data' is not present.\n",
    "  2) Train the MLP for a fixed number of epochs.\n",
    "  3) Evaluate on a held-out test split and print AUC + classification report.\n",
    "  4) Print an interpretation of the metrics and suggest next steps.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# -------------------------\n",
    "# 0. Imports\n",
    "# -------------------------\n",
    "import os\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, classification_report, confusion_matrix, precision_recall_curve\n",
    ")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# -------------------------\n",
    "# 2. Data Loading & Preprocessing\n",
    "# -------------------------\n",
    "# - If 'german.data' is missing, download from UCI.\n",
    "# - Read as space-separated file with given column names.\n",
    "# - Map label {1: Good, 2: Bad} -> {0: Good, 1: Bad}.\n",
    "# - Identify numeric vs categorical columns.\n",
    "# - Label-encode categoricals (per column) and standardize numerics (fit on train only).\n",
    "# - Train/test split with stratification to maintain class ratio.\n",
    "# - Return PyTorch tensors for model consumption.\n",
    "def load_and_preprocess_data(file_path='german.data'):\n",
    "    \"\"\"Loads, preprocesses, and splits the German Credit dataset.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X_train_t : torch.FloatTensor, shape (n_train, d)\n",
    "    X_test_t  : torch.FloatTensor, shape (n_test, d)\n",
    "    y_train_t : torch.FloatTensor, shape (n_train,)\n",
    "    y_test_t  : torch.FloatTensor, shape (n_test,)\n",
    "    feature_names : list[str]\n",
    "        Column names in the same order as the returned tensors.\n",
    "    \"\"\"\n",
    "    url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data'\n",
    "    if not os.path.exists(file_path):\n",
    "        print(\"Downloading dataset from UCI...\")\n",
    "        urllib.request.urlretrieve(url, file_path)\n",
    "\n",
    "    columns = [\n",
    "        'checking_status', 'duration', 'credit_history', 'purpose', 'credit_amount',\n",
    "        'savings_status', 'employment', 'installment_commitment', 'personal_status',\n",
    "        'other_parties', 'residence_since', 'property_magnitude', 'age',\n",
    "        'other_payment_plans', 'housing', 'existing_credits', 'job', 'num_dependents',\n",
    "        'own_telephone', 'foreign_worker', 'class'\n",
    "    ]\n",
    "    # The raw file is single-space separated, no header\n",
    "    df = pd.read_csv(file_path, sep=' ', header=None, names=columns)\n",
    "\n",
    "    # Map label to {0: Good, 1: Bad} so that 1 means \"Bad\" (positive class)\n",
    "    df['class'] = df['class'].map({1: 0, 2: 1}).astype(int)\n",
    "\n",
    "    # Separate features and target\n",
    "    X = df.drop(columns=['class']).copy()\n",
    "    y = df['class'].values\n",
    "\n",
    "    # Identify numeric vs categorical by pandas dtype\n",
    "    numerical_cols = X.select_dtypes(include=np.number).columns.tolist()\n",
    "    categorical_cols = X.select_dtypes(exclude=np.number).columns.tolist()\n",
    "\n",
    "    # Label-encode categoricals *per column*\n",
    "    # NOTE: This is a baseline choice. For production, consider embeddings/target encoding.\n",
    "    for col in categorical_cols:\n",
    "        X[col] = LabelEncoder().fit_transform(X[col])\n",
    "\n",
    "    # Train-test split (80/20) with stratification\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "\n",
    "    # Standardize numeric columns (fit on train only)\n",
    "    scaler = StandardScaler()\n",
    "    X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
    "    X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])\n",
    "\n",
    "    feature_names = X.columns.tolist()  # preserve original order\n",
    "    # Convert to tensors\n",
    "    X_train_t = torch.FloatTensor(X_train[feature_names].values)\n",
    "    X_test_t  = torch.FloatTensor(X_test[feature_names].values)\n",
    "    y_train_t = torch.FloatTensor(y_train)\n",
    "    y_test_t  = torch.FloatTensor(y_test)\n",
    "\n",
    "    return X_train_t, X_test_t, y_train_t, y_test_t, feature_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##  In class edits!  ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TabularMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims = [128, 64], dropout_rate = 0.3):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(prev_dim, hidden_dim))\n",
    "            layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "            #layers.append(nn.ReLU()) # first test used ReLU\n",
    "            layers.append(nn.GELU()) # smooth activation function as well;  learning rate did not help changing it at first but now with GELU it does help.\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "            prev_dim = hidden_dim\n",
    "        layers.append(nn.Linear(prev_dim, 1))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.network(x).squeeze(-1) # shape i (batch,_)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, device, scheduler = None, epochs = 50): # in first case scheduler is not user then in main it is\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "            loss.backward()\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "            else:\n",
    "                optimizer.step()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item() * xb.size(0)\n",
    "        # good diea to print out epch loss at each level to check\n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, device):\n",
    "    model.eval()\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in data_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            logits = model(xb)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            all_probs.append(probs.cpu().numpy())\n",
    "            all_labels.append(yb.cpu().numpy())\n",
    "    return np.concatenate(all_probs), np.concatenate(all_labels)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def metrics_and_report(y_true, y_pred_probs, threshold = 0.5):  # threshold is the net of capture so we can use a function to calculate the optimal one like normal.\n",
    "    y_pred = (y_pred_probs >= threshold).astype(int)\n",
    "    auc = roc_auc_score(y_true, y_pred_probs)\n",
    "    print(f\"AUC: {auc:.3f}\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_pred_probs)\n",
    "    print(f\"Precision: {precision.mean():.3f}\")\n",
    "    print(f\"Recall: {recall.mean():.3f}\")\n",
    "    return auc, precision.mean(), recall.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred_probs, threshold=0.5):\n",
    "    \"\"\"Plots the confusion matrix.\"\"\"\n",
    "    y_pred = (y_pred_probs >= threshold).astype(int) # Convert probabilities to binary predictions\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    X_train, X_test, y_train, y_test, feature_names = load_and_preprocess_data()\n",
    "    y_train_np = y_train.numpy().astype(int)\n",
    "    class_counts = np.bincount(y_train_np)\n",
    "    class_weights = 1. / class_counts\n",
    "    class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "    sampler = WeightedRandomSampler(\n",
    "        weights = class_weights[y_train_np],\n",
    "        num_samples=len(y_train_np),\n",
    "        replacement=True\n",
    "    )\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    test_dataset = TensorDataset(X_test, y_test)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, sampler = sampler, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size = 64, shuffle=False)\n",
    "    \n",
    "    model = TabularMLP(input_dim=X_train.shape[1]).to(device)\n",
    "    pos_weight = torch.tensor(class_counts[0]/class_counts[1], dtype = torch.float32, device = device)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001) # Adam in not vanilla, it is using a fixed learning rate.\n",
    "    #scheduler = optim.lr_scheduler.StepLR(optimizer, sep_size=5, gamma=0.5) is below\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = 50, eta_min=0.0) #50 is the epochs, eta is the minimum point of the learning rate\n",
    "\n",
    "    train(model, train_loader, criterion, optimizer, device, scheduler = scheduler, epochs=50)\n",
    "    y_pred_probs, y_true = evaluate(model, test_loader, device)\n",
    "    metrics = metrics_and_report(y_true, y_pred_probs)\n",
    "    \n",
    "    plot_confusion_matrix(y_true,y_pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/epx8hh/.conda/envs/dsvenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:182: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.803\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.54      0.68       140\n",
      "         1.0       0.45      0.88      0.60        60\n",
      "\n",
      "    accuracy                           0.65       200\n",
      "   macro avg       0.68      0.71      0.64       200\n",
      "weighted avg       0.78      0.65      0.66       200\n",
      "\n",
      "[[76 64]\n",
      " [ 7 53]]\n",
      "Precision: 0.524\n",
      "Recall: 0.711\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good AUC telling us how much we are catching are zeros.\n",
    "\n",
    "If the bad classes, ones that are struggling, getting low probabilities in the nueral network. And those that are good are getting zeros. Maybe we can penalize high probability. \n",
    "    We can change the threshold is the most direct change.\n",
    "    Use loss to balance out classes, \n",
    "    Maybe we can oversample from the bad class.\n",
    "    Maybe change the optimizer.\n",
    "\n",
    "- By changing the WeightedRandomSampler, we improved the AUC but increased the TN's, but also equaled out the TP, FP more."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dsvenv",
   "language": "python",
   "name": "dsvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
