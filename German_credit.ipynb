{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Lcocks/DS6050-DeepLearning/blob/main/German_credit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vVsCHeU2K9a4"
   },
   "source": [
    "https://colab.research.google.com/drive/1Z4h7a98YGhJ65L3_QsfEe0FOaZh8hTHT?usp=sharing\n",
    "\n",
    "https://archive.ics.uci.edu/dataset/144/statlog+german+credit+data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "H7IpHjI9K4F6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Part 1: Vanilla MLP Baseline for German Credit Risk Prediction\n",
    "Dataset (UCI ML Repository):\n",
    "- Name: Statlog (German Credit Data)\n",
    "- Direct data file used here (space-separated):\n",
    "  https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data\n",
    "- Approx. size: 1,000 rows × 20 features + 1 label (the 21st column named `class`).\n",
    "- Label encoding in the raw file: 1 = Good credit, 2 = Bad credit.\n",
    "  We remap to: 0 = Good, 1 = Bad (binary classification with \"Bad\" as the positive class).\n",
    "\n",
    "Caveats:\n",
    "- This dataset mixes numeric and categorical (string-coded) features such as 'A11'.\n",
    "  In this baseline, we use LabelEncoder per categorical column + StandardScaler on numerics.\n",
    "  A stronger approach might use embeddings or target encoding for high-cardinality variables.\n",
    "\n",
    "What you should expect:\n",
    "- Because \"Bad Credit\" is the minority class (~30% in the full dataset), a vanilla model\n",
    "  with a 0.5 threshold typically has *lower recall* on \"Bad\" (misses risky cases).\n",
    "- Still, the AUC can look decent (e.g., ~0.78–0.80) because the model ranks many\n",
    "  \"Bad\" cases higher than \"Good\" even if we choose a suboptimal decision threshold.\n",
    "\n",
    "  1) Download the dataset if 'german.data' is not present.\n",
    "  2) Train the MLP for a fixed number of epochs.\n",
    "  3) Evaluate on a held-out test split and print AUC + classification report.\n",
    "  4) Print an interpretation of the metrics and suggest next steps.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# -------------------------\n",
    "# 0. Imports\n",
    "# -------------------------\n",
    "import os\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, classification_report, confusion_matrix, precision_recall_curve\n",
    ")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# -------------------------\n",
    "# 2. Data Loading & Preprocessing\n",
    "# -------------------------\n",
    "# - If 'german.data' is missing, download from UCI.\n",
    "# - Read as space-separated file with given column names.\n",
    "# - Map label {1: Good, 2: Bad} -> {0: Good, 1: Bad}.\n",
    "# - Identify numeric vs categorical columns.\n",
    "# - Label-encode categoricals (per column) and standardize numerics (fit on train only).\n",
    "# - Train/test split with stratification to maintain class ratio.\n",
    "# - Return PyTorch tensors for model consumption.\n",
    "def load_and_preprocess_data(file_path='german.data'):\n",
    "    \"\"\"Loads, preprocesses, and splits the German Credit dataset.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X_train_t : torch.FloatTensor, shape (n_train, d)\n",
    "    X_test_t  : torch.FloatTensor, shape (n_test, d)\n",
    "    y_train_t : torch.FloatTensor, shape (n_train,)\n",
    "    y_test_t  : torch.FloatTensor, shape (n_test,)\n",
    "    feature_names : list[str]\n",
    "        Column names in the same order as the returned tensors.\n",
    "    \"\"\"\n",
    "    url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data'\n",
    "    if not os.path.exists(file_path):\n",
    "        print(\"Downloading dataset from UCI...\")\n",
    "        urllib.request.urlretrieve(url, file_path)\n",
    "\n",
    "    columns = [\n",
    "        'checking_status', 'duration', 'credit_history', 'purpose', 'credit_amount',\n",
    "        'savings_status', 'employment', 'installment_commitment', 'personal_status',\n",
    "        'other_parties', 'residence_since', 'property_magnitude', 'age',\n",
    "        'other_payment_plans', 'housing', 'existing_credits', 'job', 'num_dependents',\n",
    "        'own_telephone', 'foreign_worker', 'class'\n",
    "    ]\n",
    "    # The raw file is single-space separated, no header\n",
    "    df = pd.read_csv(file_path, sep=' ', header=None, names=columns)\n",
    "\n",
    "    # Map label to {0: Good, 1: Bad} so that 1 means \"Bad\" (positive class)\n",
    "    df['class'] = df['class'].map({1: 0, 2: 1}).astype(int)\n",
    "\n",
    "    # Separate features and target\n",
    "    X = df.drop(columns=['class']).copy()\n",
    "    y = df['class'].values\n",
    "\n",
    "    # Identify numeric vs categorical by pandas dtype\n",
    "    numerical_cols = X.select_dtypes(include=np.number).columns.tolist()\n",
    "    categorical_cols = X.select_dtypes(exclude=np.number).columns.tolist()\n",
    "\n",
    "    # Label-encode categoricals *per column*\n",
    "    # NOTE: This is a baseline choice. For production, consider embeddings/target encoding.\n",
    "    for col in categorical_cols:\n",
    "        X[col] = LabelEncoder().fit_transform(X[col])\n",
    "\n",
    "    # Train-test split (80/20) with stratification\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "\n",
    "    # Standardize numeric columns (fit on train only)\n",
    "    scaler = StandardScaler()\n",
    "    X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
    "    X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])\n",
    "\n",
    "    feature_names = X.columns.tolist()  # preserve original order\n",
    "    # Convert to tensors\n",
    "    X_train_t = torch.FloatTensor(X_train[feature_names].values)\n",
    "    X_test_t  = torch.FloatTensor(X_test[feature_names].values)\n",
    "    y_train_t = torch.FloatTensor(y_train)\n",
    "    y_test_t  = torch.FloatTensor(y_test)\n",
    "\n",
    "    return X_train_t, X_test_t, y_train_t, y_test_t, feature_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##  In class edits!  ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TabularMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims = [128, 64], dropout_rate = 0.3):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(prev_dim, hidden_dim))\n",
    "            layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "            #layers.append(nn.ReLU()) # first test used ReLU\n",
    "            layers.append(nn.GELU()) # smooth activation function as well;  learning rate did not help changing it at first but now with GELU it does help.\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "            prev_dim = hidden_dim\n",
    "        layers.append(nn.Linear(prev_dim, 1))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.network(x).squeeze(-1) # shape i (batch,_)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, device, scheduler = None, epochs = 50): # in first case scheduler is not user then in main it is\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "            loss.backward()\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "            else:\n",
    "                optimizer.step()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item() * xb.size(0)\n",
    "        # good diea to print out epch loss at each level to check\n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, device):\n",
    "    model.eval()\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in data_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            logits = model(xb)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            all_probs.append(probs.cpu().numpy())\n",
    "            all_labels.append(yb.cpu().numpy())\n",
    "    return np.concatenate(all_probs), np.concatenate(all_labels)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def metrics_and_report(y_true, y_pred_probs, threshold = 0.5):  # threshold is the net of capture so we can use a function to calculate the optimal one like normal.\n",
    "    y_pred = (y_pred_probs >= threshold).astype(int)\n",
    "    auc = roc_auc_score(y_true, y_pred_probs)\n",
    "    print(f\"AUC: {auc:.3f}\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_pred_probs)\n",
    "    print(f\"Precision: {precision.mean():.3f}\")\n",
    "    print(f\"Recall: {recall.mean():.3f}\")\n",
    "    return auc, precision.mean(), recall.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    icm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(icm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    X_train, X_test, y_train, y_test, feature_names = load_and_preprocess_data()\n",
    "    y_train_np = y_train.numpy().astype(int)\n",
    "    class_counts = np.bincount(y_train_np)\n",
    "    class_weights = 1. / class_counts\n",
    "    class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "    sampler = WeightedRandomSampler(\n",
    "        weights = class_weights[y_train_np],\n",
    "        num_samples=len(y_train_np),\n",
    "        replacement=True\n",
    "    )\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    test_dataset = TensorDataset(X_test, y_test)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, sampler = sampler, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size = 64, shuffle=False)\n",
    "    \n",
    "    model = TabularMLP(input_dim=X_train.shape[1]).to(device)\n",
    "    pos_weight = torch.tensor(class_counts[0]/class_counts[1], dtype = torch.float32, device = device)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001) # Adam in not vanilla, it is using a fixed learning rate.\n",
    "    #scheduler = optim.lr_scheduler.StepLR(optimizer, sep_size=5, gamma=0.5) is below\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = 50, eta_min=0.0) #50 is the epochs, eta is the minimum point of the learning rate\n",
    "\n",
    "    train(model, train_loader, criterion, optimizer, device, scheduler = scheduler, epochs=50)\n",
    "    y_pred_probs, y_true = evaluate(model, test_loader, device)\n",
    "    metrics = metrics_and_report(y_true, y_pred_probs)\n",
    "    \n",
    "    plot_confusion_matrix(y_true, y_pred= y_pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/epx8hh/.conda/envs/dsvenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:182: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.54      0.68       140\n",
      "         1.0       0.45      0.88      0.60        60\n",
      "\n",
      "    accuracy                           0.65       200\n",
      "   macro avg       0.68      0.71      0.64       200\n",
      "weighted avg       0.78      0.65      0.66       200\n",
      "\n",
      "[[76 64]\n",
      " [ 7 53]]\n",
      "Precision: 0.524\n",
      "Recall: 0.708\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[102]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[101]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     26\u001b[39m y_pred_probs, y_true = evaluate(model, test_loader, device)\n\u001b[32m     27\u001b[39m metrics = metrics_and_report(y_true, y_pred_probs)\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[43mplot_confusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_probs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[96]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mplot_confusion_matrix\u001b[39m\u001b[34m(y_true, y_pred)\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mplot_confusion_matrix\u001b[39m(y_true, y_pred):\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     icm = \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     sns.heatmap(icm, annot=\u001b[38;5;28;01mTrue\u001b[39;00m, fmt=\u001b[33m'\u001b[39m\u001b[33md\u001b[39m\u001b[33m'\u001b[39m, cmap=\u001b[33m'\u001b[39m\u001b[33mBlues\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      8\u001b[39m     plt.xlabel(\u001b[33m'\u001b[39m\u001b[33mPredicted\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/dsvenv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/dsvenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:467\u001b[39m, in \u001b[36mconfusion_matrix\u001b[39m\u001b[34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[32m    385\u001b[39m \n\u001b[32m    386\u001b[39m \u001b[33;03mBy definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    464\u001b[39m \u001b[33;03m(0, 2, 1, 1)\u001b[39;00m\n\u001b[32m    465\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    466\u001b[39m y_true, y_pred = attach_unique(y_true, y_pred)\n\u001b[32m--> \u001b[39m\u001b[32m467\u001b[39m y_type, y_true, y_pred = \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmulticlass\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    469\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m is not supported\u001b[39m\u001b[33m\"\u001b[39m % y_type)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/dsvenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:106\u001b[39m, in \u001b[36m_check_targets\u001b[39m\u001b[34m(y_true, y_pred)\u001b[39m\n\u001b[32m    103\u001b[39m     y_type = {\u001b[33m\"\u001b[39m\u001b[33mmulticlass\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    107\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mClassification metrics can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m targets\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    108\u001b[39m             type_true, type_pred\n\u001b[32m    109\u001b[39m         )\n\u001b[32m    110\u001b[39m     )\n\u001b[32m    112\u001b[39m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[32m    113\u001b[39m y_type = y_type.pop()\n",
      "\u001b[31mValueError\u001b[39m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good AUC telling us how much we are catching are zeros.\n",
    "\n",
    "If the bad classes, ones that are struggling, getting low probabilities in the nueral network. And those that are good are getting zeros. Maybe we can penalize high probability. \n",
    "    We can change the threshold is the most direct change.\n",
    "    Use loss to balance out classes, \n",
    "    Maybe we can oversample from the bad class.\n",
    "    Maybe change the optimizer.\n",
    "\n",
    "- By changing the WeightedRandomSampler, we improved the AUC but increased the TN's, but also equaled out the TP, FP more."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dsvenv",
   "language": "python",
   "name": "dsvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
