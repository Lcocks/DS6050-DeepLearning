{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lcocks/DS6050-DeepLearning/blob/main/German_credit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://colab.research.google.com/drive/1Z4h7a98YGhJ65L3_QsfEe0FOaZh8hTHT?usp=sharing\n",
        "\n",
        "https://archive.ics.uci.edu/dataset/144/statlog+german+credit+data"
      ],
      "metadata": {
        "id": "vVsCHeU2K9a4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7IpHjI9K4F6"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Part 1: Vanilla MLP Baseline for German Credit Risk Prediction\n",
        "Dataset (UCI ML Repository):\n",
        "- Name: Statlog (German Credit Data)\n",
        "- Direct data file used here (space-separated):\n",
        "  https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data\n",
        "- Approx. size: 1,000 rows × 20 features + 1 label (the 21st column named `class`).\n",
        "- Label encoding in the raw file: 1 = Good credit, 2 = Bad credit.\n",
        "  We remap to: 0 = Good, 1 = Bad (binary classification with \"Bad\" as the positive class).\n",
        "\n",
        "Caveats:\n",
        "- This dataset mixes numeric and categorical (string-coded) features such as 'A11'.\n",
        "  In this baseline, we use LabelEncoder per categorical column + StandardScaler on numerics.\n",
        "  A stronger approach might use embeddings or target encoding for high-cardinality variables.\n",
        "\n",
        "What you should expect:\n",
        "- Because \"Bad Credit\" is the minority class (~30% in the full dataset), a vanilla model\n",
        "  with a 0.5 threshold typically has *lower recall* on \"Bad\" (misses risky cases).\n",
        "- Still, the AUC can look decent (e.g., ~0.78–0.80) because the model ranks many\n",
        "  \"Bad\" cases higher than \"Good\" even if we choose a suboptimal decision threshold.\n",
        "\n",
        "  1) Download the dataset if 'german.data' is not present.\n",
        "  2) Train the MLP for a fixed number of epochs.\n",
        "  3) Evaluate on a held-out test split and print AUC + classification report.\n",
        "  4) Print an interpretation of the metrics and suggest next steps.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# -------------------------\n",
        "# 0. Imports\n",
        "# -------------------------\n",
        "import os\n",
        "import urllib.request\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score, classification_report, confusion_matrix, precision_recall_curve\n",
        ")\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# -------------------------\n",
        "# 2. Data Loading & Preprocessing\n",
        "# -------------------------\n",
        "# - If 'german.data' is missing, download from UCI.\n",
        "# - Read as space-separated file with given column names.\n",
        "# - Map label {1: Good, 2: Bad} -> {0: Good, 1: Bad}.\n",
        "# - Identify numeric vs categorical columns.\n",
        "# - Label-encode categoricals (per column) and standardize numerics (fit on train only).\n",
        "# - Train/test split with stratification to maintain class ratio.\n",
        "# - Return PyTorch tensors for model consumption.\n",
        "def load_and_preprocess_data(file_path='german.data'):\n",
        "    \"\"\"Loads, preprocesses, and splits the German Credit dataset.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    X_train_t : torch.FloatTensor, shape (n_train, d)\n",
        "    X_test_t  : torch.FloatTensor, shape (n_test, d)\n",
        "    y_train_t : torch.FloatTensor, shape (n_train,)\n",
        "    y_test_t  : torch.FloatTensor, shape (n_test,)\n",
        "    feature_names : list[str]\n",
        "        Column names in the same order as the returned tensors.\n",
        "    \"\"\"\n",
        "    url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data'\n",
        "    if not os.path.exists(file_path):\n",
        "        print(\"Downloading dataset from UCI...\")\n",
        "        urllib.request.urlretrieve(url, file_path)\n",
        "\n",
        "    columns = [\n",
        "        'checking_status', 'duration', 'credit_history', 'purpose', 'credit_amount',\n",
        "        'savings_status', 'employment', 'installment_commitment', 'personal_status',\n",
        "        'other_parties', 'residence_since', 'property_magnitude', 'age',\n",
        "        'other_payment_plans', 'housing', 'existing_credits', 'job', 'num_dependents',\n",
        "        'own_telephone', 'foreign_worker', 'class'\n",
        "    ]\n",
        "    # The raw file is single-space separated, no header\n",
        "    df = pd.read_csv(file_path, sep=' ', header=None, names=columns)\n",
        "\n",
        "    # Map label to {0: Good, 1: Bad} so that 1 means \"Bad\" (positive class)\n",
        "    df['class'] = df['class'].map({1: 0, 2: 1}).astype(int)\n",
        "\n",
        "    # Separate features and target\n",
        "    X = df.drop(columns=['class']).copy()\n",
        "    y = df['class'].values\n",
        "\n",
        "    # Identify numeric vs categorical by pandas dtype\n",
        "    numerical_cols = X.select_dtypes(include=np.number).columns.tolist()\n",
        "    categorical_cols = X.select_dtypes(exclude=np.number).columns.tolist()\n",
        "\n",
        "    # Label-encode categoricals *per column*\n",
        "    # NOTE: This is a baseline choice. For production, consider embeddings/target encoding.\n",
        "    for col in categorical_cols:\n",
        "        X[col] = LabelEncoder().fit_transform(X[col])\n",
        "\n",
        "    # Train-test split (80/20) with stratification\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, stratify=y, random_state=42\n",
        "    )\n",
        "\n",
        "    # Standardize numeric columns (fit on train only)\n",
        "    scaler = StandardScaler()\n",
        "    X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
        "    X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])\n",
        "\n",
        "    feature_names = X.columns.tolist()  # preserve original order\n",
        "    # Convert to tensors\n",
        "    X_train_t = torch.FloatTensor(X_train[feature_names].values)\n",
        "    X_test_t  = torch.FloatTensor(X_test[feature_names].values)\n",
        "    y_train_t = torch.FloatTensor(y_train)\n",
        "    y_test_t  = torch.FloatTensor(y_test)\n",
        "\n",
        "    return X_train_t, X_test_t, y_train_t, y_test_t, feature_names\n"
      ]
    }
  ]
}